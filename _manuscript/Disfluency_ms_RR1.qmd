---
title: "A Distributional Response Time Analysis of the Perceptual Disfluency Effect"
# If blank, the running header is the title in 
shorttitle: "Modeling Perceptual Disfluency"
# Set names and affiliations.
# It is nice to specify everyone's orcid, if possible.
# There can be only one corresponding author, but declaring one is optional.
author:
  - name: Jason Geller
    corresponding: true
    orcid: 0000-0002-7459-4505
    email: jason.geller@bc.edu
    url: www.drjasongeller.com
    # Roles are optional. 
    # Select from the CRediT: Contributor Roles Taxonomy https://credit.niso.org/
    # conceptualization, data curation, formal Analysis, funding acquisition, investigation, 
    # methodology, project administration, resources, software, supervision, validation, 
    # visualization, writing, editing
    roles:
      - Conceptualization
      - Writing
      - Data curation
      - Editing
      - Software
      - Formal analysis
    affiliations:
      - id: id1
        name: "Boston College"
        department: Department of Psychology and Neuroscience
        address: Mcguinn Hall 405
        city: Chestnut Hill
        region: MA
        country: USA
        postal-code: 02467-9991

  - name: Pablo Gomez
    orcid: 0000-0003-4180-1560
    roles:
      - Conceptualization
      - Editing
      - Formal analysis
    affiliations: 
      - id: id2
        name: "Skidmore College"
        department: Department of Psychology
  - name: Erin Buchanan
    orcid: 0000-0002-9689-4189
    roles: 
      - Editing
      - Validation
      - Formal analysis
    affiliations:
     - id: id3
       name: "Harrisburg University of Science and Technology"
       department: Analytics
  - name: Dominique Makowski 
    orcid: 0000-0001-5375-9967
    roles: 
      - Editing
      - Validation
      - Formal analysis
    affiliations:
     - id: id4
       name: "University of Sussex"
       department: School of Psychology
author-note:
  status-changes: 
    affiliation-change: ~
    deceased: ~
  disclosures:
    # Example: This study was registered at X (Identifier Y).
    study-registration: "Experiment 1A and 2 were preregistered: https://osf.io/q3fjn; https://osf.io/kjq3t."
    # Acknowledge and cite data/materials to be shared.
    data-sharing: Data, code, and materials for this manuscript can be found at  https://osf.io/6sy7k/. 
    related-report: ~
    conflict-of-interest: The authors have no conflicts of interest to disclose.
    financial-support: This work was supported by research start-up funds to JG.
    authorship-agreements: ~
abstract: "Perceptual disfluency, induced by blurring or difficult-to-read typefaces, can sometimes enhance memory retention, but the underlying mechanisms remain unclear. To investigate this effect, we manipulated blurring levels (clear, low-blur  , high-blur ) during encoding and assessed recognition performance in a surprise memory test. In Experiments 1A and 1B, response latencies from a lexical decision task were analyzed using ex-Gaussian distribution modeling and supplemented by drift diffusion modeling. Results showed that blurring differentially influenced parameters of the model, with high-blur  affecting both early and late-stage processes, while low-blur   primarily influenced early-stage processes. Recognition test results further revealed that high-blur  words were remembered better than both clear and low-blur  red words. Experiment 2 employed a semantic categorization task with a word frequency manipulation to further examine the locus of the perceptual disfluency effect. Similar to Experiments 1A and 1B, high-blur  influenced both early and late-stage processes, while low-blur   primarily affected early-stage processes. Low-frequency words exhibited greater shifting and skewing in distributional parameters, yet only high-frequency, highly blurred words demonstrated an enhanced memory effect. These findings suggest that both early and late cognitive processes contribute to the mnemonic benefits associated with perceptual disfluency. Overall, this study demonstrates that distributional and computational analyses provide powerful tools for dissecting encoding mechanisms and their effects on memory, offering valuable insights into models of perceptual disfluency."

keywords: [disfluency, LDT, DDM, ex-Gaussian, distributional analyses, word recognition]
floatsintext: true
numbered-lines: true
bibliography: references.bib
suppress-title-page: false
link-citations: false
mask: false
masked-citations:
draft-date: false
lang: en
language: 
  citation-last-author-separator: "and"
  citation-masked-author: "Masked Citation"
  citation-masked-date: "n.d."
  citation-masked-title: "Masked Title"
  email: "drjasongeller@gmail.com"
  title-block-author-note: "Author Note"
  title-block-correspondence-note: "Correspondence concerning this article should be addressed to"
  title-block-role-introduction: "Author roles were classified using the Contributor Role Taxonomy (CRediT; https://credit.niso.org/) as follows:"
word-count: true
format:
 #apaquarto-docx: default
 #apaquarto-html: default
 apaquarto-typst: default
  
execute: 
  echo: false
  warning: false
  message: false
  fig-align: "center"
  tbl-align: "center"
  keep-with-next: true
  code-overflow: wrap
  cache: true
  ft-align: "center"
  out-width: 50%
  fig-dpi: 500

knitr:
  opts_chunk: 
    dev: "ragg_png"
---

```{r}
#| eval: false
required_packages <- c(
  "brms",
  "cmdstanr",
  "colorspace",
  "cowplot",
  "data.table",
  "easystats",
  "emmeans",
  "flextable",
  "ggeffects",
  "ggdist",
  "ggrepel",
  "ggtext",
  "hypr",
  "knitr",
  "officer",
  "patchwork",
  "ragg",
  "tidybayes",
  "tidylog",
  "tinytable",
  "tidyverse"
)

install_missing <- setdiff(required_packages, rownames(installed.packages()))
if (length(install_missing) > 0) {
  install.packages(install_missing)
}
```

```{r}
#| label: load packages

library(easystats)
library(tidyverse)
library(patchwork)
library(knitr)
library(data.table)
library(ggrepel)
library(brms)
library(ggdist)
library(emmeans)
library(tidylog)
library(tidybayes)
library(hypr)
library(colorspace)
library(ragg)
library(cowplot)
library(ggtext)
library(ggdist)
library(flextable)
library(officer)
library(cmdstanr)
library(tinytable)
library(tibble)

options(timeout = 10000)
```

```{r}

# inf does not display correctly

# Check if ER column value is numeric, if not, replace with Inf
process_ER_column <- function(x) ifelse(is.infinite(x), "Inf", x)
```

```{r}
#| label: ggplot theme
#| echo: false

# Set up your theme
bold <- element_text(face = "bold", color = "black", size = 16) #axis bold
theme_set(theme_minimal(base_size = 16, base_family = "Times New Roman"))
theme_update(
  panel.grid.major = element_line(color = "grey92", linewidth = .4),
  panel.grid.minor = element_blank(),
  axis.title.x = element_text(color = "grey30", margin = margin(t = 7)),
  axis.title.y = element_text(color = "grey30", margin = margin(r = 7)),
  axis.text = element_text(color = "grey50"),
  axis.ticks = element_line(color = "grey92", linewidth = .4),
  axis.ticks.length = unit(.6, "lines"),
  legend.position = "top",
  plot.title = element_text(
    hjust = 0,
    color = "black",
    family = "Times New Roman",
    size = 21,
    margin = margin(t = 10, b = 35)
  ),
  plot.subtitle = element_text(
    hjust = 0,
    face = "bold",
    color = "grey30",
    family = "Arial",
    size = 14,
    margin = margin(0, 0, 25, 0)
  ),
  plot.title.position = "plot",
  plot.caption = element_text(
    color = "grey50",
    size = 10,
    hjust = 1,
    family = "Times New Roman",
    lineheight = 1.05,
    margin = margin(30, 0, 0, 0)
  ),
  plot.caption.position = "plot",
  plot.margin = margin(rep(20, 4))
)
```

```{r}
#| label: ex-guass brms family file

source(here::here("exguass_reparm.R"))

# load ex-gauss family with more traditional mu, sigma, tau
```

```{r}
#| eval: false
# check if data is in folder, otherwise download itAdd commentMore actions
check_and_download <- function(filename, url, data_dir = "data") {
  # Construct full file path
  file_path <- file.path(data_dir, filename)

  # Check if file exists
  if (!file.exists(file_path)) {
    message("File not found, downloading: ", filename)

    # Create directory if it doesn't exist
    if (!dir.exists(data_dir)) {
      dir.create(data_dir, recursive = TRUE)
    }

    # Download the file
    download.file(url, destfile = file_path, mode = "wb")
    message("Download complete: ", file_path)
  } else {
    message("File already exists: ", file_path)
  }

  return(file_path)
}

data_files <- tribble(
  ~filename,
  ~url,
  "cleaned_context_rt.csv",
  "https://osf.io/xv5bd/download",
  "weiner_diff_1.rds",
  "https://osf.io/hqauz/download",
  "blmm_sdt_context.csv",
  "https://osf.io/xjvc7/download",
  "cleaned_nocontext_rt.csv",
  "https://osf.io/excgd/download",
  "cond_blmm_sdt_contextnot.csv",
  "https://osf.io/jw2gx/download",
  "SC_blmm_sdt.csv",
  "https://osf.io/eapu5/download",
  "fit_acc_context_1a.rds",
  "https://osf.io/xkgqj/download",
  "fit_sc.rds",
  "https://osf.io/m4nv5/download",
  "blmm_sdt_expt1a_priors_hblbc2.rds",
  "https://osf.io/dbfwa/download",
  "fit_acc_weak_nocontext.rds",
  "https://osf.io/p9xat/download",
  "ex_gauss_1b.rds",
  "https://osf.io/ajwe4/download",
  "weiner_diff_noc (1).rds",
  "https://osf.io/gy5ab/download",
  "blmm_sdt_nc_hblbc.rds",
  "https://osf.io/yfzke/download",
  "SC_rt_cleaned.csv",
  "https://osf.io/29hnd/download",
  "acc_blmm_sc_hblbc_moreints.rds",
  "https://osf.io/2yb7g/download",
  # "mod_exgauss_HBLBC.rds", "http://osf.io/uwcjf/download",
  "blmm_sdt_sc_hblbC.rds",
  "https://osf.io/kh43z/download"
)

# This assumes your dataframe has columns filename and url
pwalk(data_files, function(filename, url) {
  check_and_download(filename, url)
})
```

**We live in a world that is, even for adults, “blooming and buzzing with confusion” [@james1890, p.488]. Yet we can still decipher cursive writing or follow conversations in noisy bars. This ability to cope with a noisy, confusing environment has long been studied at the intersection of education and cognitive psychology. Decades of work show that encoding difficulty can enhance long-term memory. Although people often assume that easier learning is better, many findings demonstrate the opposite: under certain conditions, making learning more effortful can improve retention. This phenomenon, known as the *desirable difficulties* principle [@bjork_making_2011], includes robust effects such as spacing study sessions [@carpenter2022], interleaving concepts rather than blocking them [@rohrer2007], and generating or retrieving information instead of simply re-reading it [@roediger2006; @slamecka1978].**

**One straightforward example involves altering the perceptual characteristics of study materials to make them harder to process. A growing literature shows that such manipulations can improve memory [e.g., @geller2018; @geller2021; @halamish2018; @rosner2015], a benefit referred to as the *perceptual disfluency effect* [see @geller2018].**

## The Perceptual Disfluency Effect

**The link between perceptual disfluency and memory dates back to the late 1980s. @nairne1988 , using the term perceptual-interference effect, employed backward masking with hash marks (e.g., ####) to make word encoding more difficult. Since then, a range of manipulations has been shown to elicit similar effects, including high-level blurring [@rosner2015], word inversion [@sungkhasettee2011], small text size [@halamish2018], handwritten cursive [@geller2018], and unusual typefaces [@geller2021; @weissgerber2017; @weltman2014].**

**Because these manipulations are simple to implement, researchers quickly began touting their educational potential. Interest grew following @diemand-yauman2011, who reported that presenting material in disfluent typefaces (e.g., Comic Sans, Bodoni MT, Haettenschweiler, Monotype Corsiva) enhanced memory both in the lab and in high school classrooms across multiple content areas.**

**However, evidence for the effect has been inconsistent. A striking example is Sans Forgetica, a font designed to promote memory through slanted, gapped letters, forcing individuals to “generate” the missing parts of each word [@earp2018]. Despite early claims, multiple studies have failed to replicate its benefits, finding it produces no memory benefit over and beyond normal fonts [@cushing2022; @geller2020; @huff2022; @roberts2023; @taylor2020; @wetzler2021]. Similar null results have been reported for small fonts [@rhodes2008], degraded auditory stimuli [@rhodes2009], minor blurring [@yue2013], and alternative typefaces [@rummer2015].**

**Given these mixed findings, recent work has focused on boundary conditions. @geller2018 showed a “Goldilocks” zone: memory benefits emerge only when stimuli are moderately, not excessively, difficult to read (e.g., easy-to-read cursive). @geller2021 further demonstrated that disfluency effects are stronger when test expectancy is low, reasoning that explicit test instructions lead participants to process all items deeply, reducing any added benefit of disfluency. Individual differences also play a role; for instance, @eskenazi2021 found that strong spellers gained more from disfluent fonts than weaker spellers.**

**Overall, perceptual disfluency can enhance memory in specific contexts but appears limited as an educational intervention, where students are typically aware of upcoming tests. Nonetheless, as @geller2021 argue, disfluency may hold practical value in everyday settings where memory is often incidental. The key challenge is to predict when and where such effects will reliably occur.**

## Theoretical Accounts of the Disfluency Effect

**To apply perceptual disfluency effectively in real-world settings, its underlying mechanisms must be better understood. Several theories have been proposed, with @geller2018 reviewing two major accounts.** **The metacognitive account [@alter2007; @pieger2016] views disfluency as a cue that prompts greater cognitive control and regulatory processing. Here, disfluency is detected after stimulus identification, and the specific type of disfluency is less important than the learner’s perception that material is difficult, which triggers regulatory processes. The compensatory processing account [@mulligan1996], rooted in the interactive activation model of word recognition [@mcclelland1981], argues that disfluency enhances memory by recruiting top-down support from lexical and semantic representations. When input is noisy (e.g., masked or blurred), higher-level knowledge feeds back to aid recognition, and this deeper processing strengthens memory.**

More recently, Ptok and colleagues proposed a limited-capacity, stage-specific model [@ptok2019; @ptok2020]. They showed that memory benefits from encoding conflict depend on (1) the processing level engaged by the task and (2) metacognitive monitoring and control. Across six experiments, they found improved recognition when target words were paired with incongruent semantic distractors (e.g., *Chair – Alive* vs. *Chair – Inanimate*), but not with incongruent response distractors (e.g., *Lisa – left/right*). Both conditions slowed responses, but only semantic conflict boosted memory, suggesting the effect arises when tasks emphasize meaning. Pupillometry--a measure of cognitive effort [see @mathot2018; @vanderwel2018 for reviews] confirmed that both types of conflict increase effort, yet only semantic conflict translated into memory benefits. Importantly, the effect vanished when endogenous attention was constrained (e.g., by using a chin-rest), mirroring perceptual disfluency findings: disfluency benefits are eliminated by test expectancy [@geller2021] or judgments of learning (JOLs; ) [@rosner2015; @besken2013].\*\*

**Together, these accounts highlight different loci for the disfluency effect. The metacognitive account situates it post-lexically, after word recognition. The compensatory account links it directly to recognition, with disfluent words receiving more top-down support. The stage-specific model associates it with semantic-level processing, while also incorporating attentional and control processes that modulate when disfluency effects appear.**

## Moving Beyond the Mean: Modeling Reaction Time (RT) Distributions

### Ex-Gaussian Distribution

**To test the stages involved in the perceptual disfluency effect, researchers need methods that provide a finer-grained analysis of encoding. In learning and memory research, differences between fluent and disfluent conditions are typically assessed with mean reaction times [@geller2018; @geller2021; @rosner2015]. Although standard, mean-RT analyses have been criticized for obscuring important distributional patterns [@balota2011].**

**Mean-RTs are unimodal, positively skewed, and often heteroscedastic, violating assumptions of widely used linear models [@wilcox1998]. The use of mean RTs can mask effects that selectively influence distributional shape (e.g., the slow tail), central tendency, or both. Moreover, RTs reflect a blend of decisional and non-decisional processes, limiting inferences about specific cognitive stages.**

**A widely used alternative is the ex-Gaussian distribution [@balota2011; @ratcliff1978], which decomposes RTs into three parameters:** $\mu$ **(mean of the Gaussian component, reflecting typical response speed),** $\sigma$ **(its standard deviation), and** $\tau$ **(mean/SD of the exponential component, reflecting the slow tail). The overall mean equals** $\mu$ **+** $\tau$**, and the SD is** $\sqrt{\sigma^2 + \tau^2}$**. This decomposition allows researchers to distinguish between manipulations that shift the whole distribution, stretch the tail, or both.**

**For example, @heathcote1991 analyzed Stroop effects with an ex-Gaussian model. They found facilitation and interference effects on μ, interference on σ, and interference on** $\tau$ **. Mean RT analysis revealed only interference, as facilitation on μ and interference on τ canceled out—a finding hidden without distributional modeling.**

**Exploring effects from a distributional perspective has provided a richer understanding of how different experimental manipulations affect word recognition. Experimental manipulations can produce several distinct patterns. One pattern involves a shift of the entire RT distribution to the right, without increasing the tail or skew. A pattern such as this would suggest a general effect and would manifest as an effect on** $\mu$**, but not** $\tau$**. As an example, semantic priming effects--where responses are faster to targets when preceded by a semantically related prime compared to an unrelated prime--can be nicely explained by a simple shift in the RT distribution [@balota2008]. Alternatively, an experimental manipulation could produce a pattern where the RT distribution is skewed or stretched in the slower condition. This suggests that the manipulation only impacts a subset of trials, and is visible as an increase in** $\tau$**. An example of an effect that only impacts** $\tau$ **is the transposed letter effect in visual word recognition [@johnson2012]. The transposed letter (TL) effect involves misidentification of orthographically similar stimuli that with transposed internal like, like mistaking "JUGDE" for "JUDGE" [@perea2003]. Finally, you could observe a pattern wherein an experimental manipulation results in both changes in** $\mu$ **and** $\tau$**, which would shift and stretch the RT distribution. Recognizing low-frequency words have been shown to not only shift the RT distribution, but also stretch the RT distributions [@andrews2001; @balota1999; @staub2010].**

**Although largely descriptive, the model has been used to link parameters to processing stages. For instance,** $\mu$ **and** $\sigma$ **have been tied to early, automatic processes such as spreading activation in semantic priming [@balota2008; @dewit2015]. Conversely,** $\tau$ **has been linked to later, controlled processes involving attention and working memory [@balota1999; @kane2003; @Fitousi2020]. For example,** $\tau$ **differences in the transposed-letter effect have been attributed to post-lexical checking on a subset of trials [@johnson2012]. Still, mapping distributional parameters onto cognitive processes remains debated and should be interpreted carefully [@matzke2009; @heathcote1991].**

## Goals of the Present Experiments

I**n the present experiments, we pursued two aims related to perceptual disfluency. The first was to examine the replicability of the perceptual disfluency effect. To maximize the likelihood of observing this effect, we employed a manipulation that has previously been shown to enhance memory: perceptual blurring. @rosner2015 demonstrated across several studies that high level blurring, but not low level blurring can boost memory in a recognition memory test [also see @geller2018]. Thus, not all disfluency manipulations are created equal. Different perceptual manipulations affect processing in distinct ways, making it critical to identify which manipulations reliably produce disfluency effects and at what stage of processing. Following @rosner2015, we presented participants with clear words (no blur), low-blurred words (5% Gaussian blur), and high-blurred words (15% Gaussian blur).**

**The second, more pivotal aim was to expand the methodological toolkit for investigating perceptual disfluency during encoding. To this end, we applied the ex-Gaussian distribution, which allows RT distributions to be decomposed into parameters reflecting different stages of processing. This approach offers a richer perspective beyond what mean response times alone can reveal. The ex-Gaussian distribution is widely used in the word recognition field [@balota2008], and its parameters are both interpretable and straightforward to implement. By using a distributional approach coupled with varying levels of perceptual disfluency, we aim to clarify the specific processing stages at which perceptual disfluency affects encoding, thereby providing a more mechanistic account of when disfluency enhances memory and when it does not.**

### Predictions

@tbl-predictions **summarizes each theoretical account of perceptual disfluency and their predicted outcomes. Some of these accounts are articulated verbally and can be formalized in different ways. We made a good-faith effort to translate these verbal descriptions into models, while recognizing that reasonable researchers may make alternative modeling choices—an unavoidable reality of scientific inference [see @mcelreath2020statistical].**

**The ex-Gaussian distribution provides a descriptive framework for assessing how disfluency manipulations affect encoding. Each account makes specific predictions about the loci of the perceptual disfluency effect, which can be mapped onto model parameters.**

**If the metacognitive account [e.g., @alter2007; @pieger2016] holds, and the effect arises primarily at a post-lexical stage, one would expect a lengthening of the distribution tail (increases in** $\tau$**) for blurred relative to clear words. Importantly, this perspective suggests that memory performance may not differ between high- and low-blurred words, given that perceptual disfluency is assumed to be largely subjective in nature.**

**In contrast, the compensatory processing account [@mulligan1996] would predict a shift in the distribution (increase in** $\mu$**) for high-blurred words compared to low- and no-blurred words and better memory. Memory effects arising in this account are thought to be purely lexical/semantic. This expectation is in line with findings from @rosner2015, who reported that highly blurred words are associated with longer latencies, increased error rates, and better recognition memory.**

**If the disfluency effect reflects both early and late processing, the stage-specific account [@ptok2019; @ptok2020] predicts that high-blur (vs. clear/low-blur ) will increase both \$\\mu\$ (overall rightward shift) and \$\\tau\$ (heavier tail). Similar encoding patterns have been observed with hard-to-read handwriting [e.g., @perea2016; @vergara-martínez2021]. Because low-blur is unlikely to recruit substantial post-lexical control, the account predicts no reliable change in either parameter for low-blur items.**

```{r}
#| label: tbl-predictions
#| tbl-cap: "Mapping model predictions to theoretical constructs"
#| apa-note: "↑ = bigger ; ↓ = smaller;  x = no effect on parameter of interest"

data <- data.frame(
  Account = rep(
    c("Meta-cognitive", "Compensatory-processing", "Stage-specific"),
    each = 2
  ),
  Description = rep(
    c(
      "Perceptual disfluency affects meta-cognitive processes via increased system 2 processing",
      "Perceptual disfluency affects the word recognition process",
      "Disfluency effects rely on (1) the stage or level of processing tapped by the task and (2) monitoring and control processes"
    ),
    each = 2
  ),
  Loci = rep(
    c("Post-lexical", "Lexical/semantic", "Lexical/semantic and Post-lexical"),
    each = 2
  ),
  Contrast = c(
    "High blur vs. Low blur/Clear",
    "Low blur vs. Clear",
    "High blur vs. Low blur/Clear",
    "Low blur vs. Clear",
    "High blur vs. Low blur/Clear",
    "Low blur vs. Clear"
  ),
  ExGaussianPredictions = c(
    "μ: ×\nτ: ↑",
    "μ: ×\nτ:↑ ", # Meta-cognitive
    "μ: ↑\nτ: ×",
    "μ: x\nτ: x", # Compensatory-processing (updated)
    "μ: ↑\nτ: ↑",
    "μ: ↑\nτ: ×" # Stage-specific
  ),
  QuantilePlots = c(
    "Late Difference",
    "Late Difference",
    "Complete Shift",
    "No Difference",
    "Complete Shift + Late Differences",
    "No Difference"
  ),
  RecognitionMemoryPredictions = c(
    "High > Low/clear",
    "Low > clear", # Meta-cognitive
    "High > Low/clear",
    "Low  =  clear", # Compensatory-processing (updated)
    "High > Low/clear",
    "Low  =  clear" # Stage-specific
  ),
  stringsAsFactors = FALSE
) |>
  dplyr::mutate(
    Account = ifelse(duplicated(Account), "", Account),
    Description = ifelse(duplicated(Description), "", Description),
    Loci = ifelse(duplicated(Loci), "", Loci)
  )

ft <- flextable(data) |>
  set_header_labels(
    Account = "Account",
    Description = "Description",
    Loci = "Loci",
    Contrast = "Contrast",
    ExGaussianPredictions = "Ex-Gaussian Predictions",
    QuantilePlots = "Quantile Plots",
    RecognitionMemoryPredictions = "Recognition Memory Predictions"
  ) |>
  merge_v(j = c("Account", "Description", "Loci")) |>
  align(
    j = c("Account", "Description", "Loci", "Contrast"),
    align = "left",
    part = "body"
  ) |>
  align(
    j = c(
      "ExGaussianPredictions",
      "QuantilePlots",
      "RecognitionMemoryPredictions"
    ),
    align = "center",
    part = "body"
  ) |>
  width(j = "Account", width = 1) |>
  width(j = "Description", width = 2) |>
  width(j = "Loci", width = 1) |>
  width(j = "Contrast", width = 1) |>
  width(j = "ExGaussianPredictions", width = 1.5) |>
  width(j = "QuantilePlots", width = 1.5) |>
  width(j = "RecognitionMemoryPredictions", width = 1.5) |>
  bold(part = "header")

ft

```

# Experiment 1A: Context Reinstatement

In Experiment 1A, we collected RTs from a lexical decision task (LDT) during encoding followed by a surprise recognition memory test. Using a two-choice task, like the LDT, allowed us to examine how perceptual disfluency affects encoding processes using mathematical models. Based on previous research [@geller2021], there was no mention of the recognition test when participants signed up for the study to give us the best chance of observing a disfluency effect.

## Method

### Transparency and Openness

This study complies with transparency and openness guidelines. The preregistered analysis plan for this experiment can be found here: https://osf.io/q3fjn. All raw and summary data, materials, and *R* scripts for pre-processing, analysis, and plotting can be found at https://osf.io/6sy7k/.[^1] All deviations and changes from the preregistration are noted herein.

[^1]: To promote transparency and reproducibility, this paper was written in I [@R] using Quarto [@Allaire_Quarto_2024], an open-source publishing system that allows for dynamic and static documents. This system allows figures, tables, and text to be programmatically included directly in the manuscript, ensuring that all results are seamlessly integrated into the document. We used the *rix* [@rix] package which harnesses the power of the nix [@nix] ecosystem to help with computational reproducibility. This package captures not only the *R* packages used to generate the manuscript but also the system dependencies at run-time. As a result, others can easily reproduce the environment by installing the Nix package manager and using the included `default.nix` file. The `README` file in the GitHub repository contains detailed information on how to set up and reproduce the contents of the current manuscript. We have also included a video tutorial. We hope these supplemental materials will make it easier for researchers to apply this code to their own research.

### Participants

**All participants were recruited through the** Rutgers University subject pool (SONA system). **We preregistered a sample size of 216 participants. A design of this size provides at least 90% power to detect effect sizes of** $\delta \geq 0.20$**, assuming a one-sided test with** $\alpha =0.05$**. A total of 263 participants completed the study. Per our exclusion criteria, 15 participants were removed for completing the experiment more than once, and 16 were removed for accuracy below 80%. No participants were excluded for being non-native English speakers or under 18 years of age. To account for oversampling and to ensure equal numbers across lists, we randomly selected 36 participants from each list, yielding a final sample of 216 participants.**

**The study protocol was reviewed and approved by the Rutgers University Institutional Review Board.**

### Apparatus and stimuli

The experiment was run using PsychoPy software and hosted on Pavlovia (www.pavlovia.org). You can see an example of the experiment by navigating to this website: <https://run.pavlovia.org/Jgeller112/ldt_dd_l1_jol_context>.

We used 84 words and 84 nonwords for the LDT. Words were obtained from the *LexOPS* package [@taylor2020a]. All of our words were matched on a number of different lexical dimensions. All words were nouns, 4-6 letters in length, had a known word recognition rate of 90–100%, had a low neighborhood density (OLD20 score between 1-2), high concreteness, imageability, and word frequency. Our nonwords were created using the English Lexicon Project [@balota2007]. Stimuli can be found at our OSF project page cited above.

#### Blurring

Blurred stimuli were processed through the {*imager}* package [@imager] and a personal script (https://osf.io/gr5qv). Each image was processed through a high-blur filter (Gaussian blur of 15) and low-blur filter (Gaussian blur of 10). These pictures were then imported into PsychoPy as picture files. See @fig-blur for examples how clear, low-blur red, and high-blur red words appeared in the experiment.

```{r}
#| label: fig-blur
#| fig-cap: Clear (left), Low  blur (10% blur) (right), and High blur (15% blur) (center) examples.
# Combine images in one figure
include_graphics("figures/blur.jpg")
```

### Design

We created two lists: 1) one list (84 words; 28 clear, 28 low-blur , and 28 high-blur ) served as a study (old) list for the LDT task while the 2) other list served as a test (new) list (84 words; 28 clear, 28 low-blur , and 28 high-blur ) for our recognition memory test that occurred after the LDT. We counterbalanced each list so each word served as an old word and a new world and were presented in clear, low-blur red, and high-blur red across participants. This counterbalancing resulted in six lists. Lists were assigned to participants so that across participants each word occurs equally often in the six possible conditions: clear old, low-blur old, high-blur old, clear new, low-blur new, and high-blur new. For the LDT task, we generated a set of 84 legal nonwords that we obtained from the English Lexicon Project. These 84 nonwords were used across all 6 lists.

### Procedure

The experiment consisted of two phases: an encoding phase (LDT) and a test phase. During the encoding phase, a fixation cross appeared at the center of the screen for 500 ms. The fixation cross was immediately replaced by a letter string in the same location. To continue to the next trial, participants had to decide if the letter string presented on screen was a word or not by either pressing designated keys on the keyboard ("m" or "z") or by tapping on designated areas on the screen (word vs. nonword) if they were using a cell phone/tablet. After the encoding phase, participants were given a surprise old/new recognition memory test. During the test phase, a word appeared in the center of the screen that either had been presented during study ("old") or had not been presented during study ("new"). Old words occurred in their original typeface, and following the counterbalancing procedure, each of the new words was presented as clear, low-blur red, or high-blur red. All words were individually randomized for each participant during both the study and test phases and progress was self-paced. After the experiment, participants were debriefed. The entire experiment lasted approximately 15 minutes.

### Data Analysis Plan

All models were fit in *R* [@R] using the Stan modeling language [@grant2017] via the {*brms}* package [@brms]. We used maximal random-effects structures justified by the design [@barr2013].

We ran four chains of 5,000 MCMC iterations (1,000 warm-up), totaling 16,000 post-warm-up samples. Model quality was checked via prior/posterior predictive checks, $\hat{R}$, and effective sample size [ESS; @vehtari2021]. Convergence was assessed using $\hat{R}$ (target ≤ 1.01) and effective sample size (ESS ≥ 1000) [@brms]. Default (non-informative) priors were used for most parameters. Weakly informative priors were used for population-level parameters to enable Bayes factor (Evidence Ratio; ER) calculations for two sided-hypotheses against a point null. Full prior specifications are available in the Quarto source file on OSF: <https://osf.io/6vew2>.

We report posterior means and 90% credible intervals (CrIs) for one-sided hypotheses (preregistered differences), and 95% CrIs for two-sided hypotheses (against zero). Estimated marginal means were extracted using a combination of *emmeans* [@emmeans] and {*brms*}[@brms]. Additionally, we report the posterior probability that an effect lies in a particular direction and ER, which is a generalization of the Bayes factor for directional hypotheses[^2]. An ER \> 3 indicates moderate to strong evidence for the hypothesis; ER \< 0.3 indicates support for the alternative; and ER values between 0.3 and 3 are considered inconclusive. ERs were also used to assess point-null hypotheses ($\delta = 0$). Hypotheses were considered supported if zero was excluded from the CrI, The posterior probability approached 1, and ER was \> 3.

[^2]: **This is supported by the {brms} package developer and is discussed in this Github post: <https://github.com/paul-buerkner/brms/issues/311>. However, there is much debate on the use of BFs.**

For all models, we applied ANOVA-style (effects) coding using contrast variables. For the blur factor in Experiments 1A, 1B, and 2, we defined two orthogonal contrasts to capture the primary comparisons of interest. Contrast 1 compared high-blur against the average of clear and low-blur , coding high-blur as 0.5 and both clear and low-blur as –0.5. Contrast 2 isolated the difference between low-blur and clear, with low-blur coded as 0.5, clear as –0.5, and high-blur as 0. In Experiment 2, we also included a Frequency factor, with High Frequency coded as 0.5 and Low Frequency as –0.5. Although these contrasts deviate from our preregistered comparisons, we believe they offer a more targeted test of our hypotheses. For transparency, we provide all pairwise comparisons in the accompanying visualizations.

#### Accuracy

Accuracy (coded as correct \[1\] vs. incorrect \[0\]) was modeled using a Bayesian logistic regression with a Bernoulli distribution.

#### Ex-Gaussian

We modeled response times with an ex-Gaussian distribution[^3], allowing the Gaussian mean/location ($\mu$), the Gaussian standard deviation ($\sigma$) and the exponential scale ($\beta = 1/\lambda$) to vary by condition. Please note that when we refer to $\beta$ we are referring to $\tau$. \*\*When fitting the ex-Guassian distribution we use the identity link for $\mu$, and the log link for $\sigma$ and $\beta$ .\*\*

[^3]: The parameterization used by {brms} does not match the standard formulation of the ex-Gaussian distribution. **In the parameterization used by {brms}** $\mu$ **is the mean of the entire distribution, not just the Gaussian part.** A custom script was implemented to recover the traditional parameters and can be found here: <https://osf.io/b352t>.

#### Quantile and Delta Plots

In addition to ex-Gaussian analyses, we provide a graphical description of changes to the RT distribution using quantile and delta plots [@balota2008; @dejong1994]. The process of visualization through quantile analysis can be broken down into four distinct steps:

1.  Sorting and plotting: For correct trials, RTs are arranged in ascending order within each condition. We then plot the average of the specified quantiles (e.g., .1, .2, .3, .4, .5, .9).

2.  Quantile averaging across participants: The individual quantiles for each participant are averaged, a concept reminiscent of Vincentiles.

3.  Between-condition quantile averaging: The average for each quantile is computed between the conditions.

4.  Difference calculation: We determine the difference between the conditions, ensuring the sign of the difference remains unchanged.

Typically, there are four observable patterns in the graphical depiction. No observable difference occurs when the conditions do not show any noticeable distinction. Late differences emerge when increasing differences appear later in the sequence, suggesting that the conditions diverge over time. A complete shift indicates a consistent difference across all quantiles, signaling an overall shift in the distribution. Finally, early differences reveal distinctions early in the reaction time distribution, suggesting an initial divergence between conditions.

#### Recognition Memory

Following recent trends [see @zloteanu2024], recognition memory data were analyzed using a Bayesian generalized linear multilevel model (GLMM; a Bernoulli distribution with a probit link). Here the response of the participant ("say old" vs. "say new") are modeled as function of item status ("is old" vs. "is new") and condition.

Bayesian GLMMs provide a more precise and flexible approach than traditional signal detection theory analyses. Following Signal Detection Theory [SDT; @green1966], participant responses can be classified as hits, correct rejections, misses, or false alarms, depending on the item status ("old" vs. "new"). In the probit regression framework, the interaction between item status and a predictor of interest corresponds directly to *d′*, while the main effects reflect response criterion [@decarlo1998; for a detailed discussion of Bayesian SDT modeling see @zloteanu2024]. Note that the model parameterization reflects *–c* (i.e., reversed sign) and this facet is what is reported in the paper. For visualization purposes, we use the conventional parameterization: positive values indicate more conservative responding, and negative values indicate a more liberal bias.

## Results

All models presented no divergences, and all chains mixed well and produced comparable estimates ($\hat{R}$ \< 1.01 and ESS \> 1000).

### Accuracy

```{r}
#The data file is cleaned (participants >=.8, no duplicate participants, no participants < 17. )
# get data from osf

blur_acc <- read_csv("https://osf.io/xv5bd/download") |>
dplyr::filter(lex == "m")

blur_acc_new <- blur_acc  |>
  dplyr::filter(rt >= .2 & rt <= 2.5)
```

The analysis of accuracy is based on `r dim(blur_acc_new)[1]` data points, after removing fast (\< .2 s) and slow (\> 2.5 s) RTs (`r round(1-dim(blur_acc_new)[1]/dim(blur_acc)[1], 3)`).

```{r}
#| echo: false

## Contrasts
#hypothesis

# Create custom contrast matrix manually
contrast_matrix <- matrix(
  c(
    -.5,
    -.5, # C
    .5,
    0, # HB
    -.5,
    .5
  ), # LB
  ncol = 2,
  byrow = TRUE
)

blur_acc_new$blur <- as.factor(blur_acc_new$blur)

# Assign to factor
contrasts(blur_acc_new$blur) <- contrast_matrix
```

```{r}
#| eval: false
#| echo: false

#weak prior
prior_exp1 <- c(set_prior("cauchy(0,.35)", class = "b"))

#fit model
fit_acc_weak <- brm(
  corr ~ blur + (1 + blur | participant) + (1 + blur | string),
  data = blur_acc_new,
  warmup = 1000,
  iter = 5000,
  chains = 4,
  init = 0,
  family = bernoulli(),
  cores = 4,
  prior = prior_exp1,
  control = list(adapt_delta = 0.9),
  backend = "cmdstanr",
  save_pars = save_pars(all = T),
  sample_prior = T,
  seed = 666,
  threads = threading(4),
  file = "fit_acc_context"
)
```

```{r}
acc_c <- read_rds("https://osf.io/xkgqj/download")
fit_acc_noc <- read_rds("https://osf.io/p9xat/download")

# Run hypotheses
a <- hypothesis(acc_c, "blur1 < 0") # high-blur  < (low-blur   + clear)/2
b <- hypothesis(acc_c, "blur2 = 0") # low-blur   < clear

# Round numeric outputs
round_hypothesis <- function(hyp) {
  hyp$hypothesis <- hyp$hypothesis |>
    mutate(across(where(is.numeric), round, 3))
  hyp
}

a <- round_hypothesis(a)
b <- round_hypothesis(b)

# Combine and format table
tab_acc1 <- bind_rows(a$hypothesis, b$hypothesis) |>
  mutate(
    Hypothesis = c(
      "High blur < (Low blur + Clear)",
      "Low blur < Clear"
    ),
    `CrI*` = str_glue("[{CI.Lower}, {CI.Upper}]")
  ) |>
  rename(
    Mean = Estimate,
    SE = Est.Error,
    ER = Evid.Ratio,
    `Posterior Prob` = Post.Prob
  ) |>
  select(Hypothesis, Mean, SE, `CrI*`, ER, `Posterior Prob`) |>
  mutate(Experiment = c("Experiment 1A", "")) |>
  relocate(Experiment, .before = everything())

# Run hypotheses
a <- hypothesis(fit_acc_noc, "blur1 < 0") # high-blur  < (low-blur   + clear)/2
b <- hypothesis(fit_acc_noc, "blur2 = 0") # low-blur   < clear

# Round numeric outputs
round_hypothesis <- function(hyp) {
  hyp$hypothesis <- hyp$hypothesis |>
    mutate(across(where(is.numeric), round, 3))
  hyp
}

a <- round_hypothesis(a)
b <- round_hypothesis(b)

# Combine and format table
tab_acc2 <- bind_rows(a$hypothesis, b$hypothesis) |>
  mutate(
    Hypothesis = c(
      "High blur < (Low blur + Clear)",
      "Low blur = Clear"
    ),
    `CrI*` = str_glue("[{CI.Lower}, {CI.Upper}]")
  ) |>
  rename(
    Mean = Estimate,
    SE = Est.Error,
    ER = Evid.Ratio,
    `Posterior Prob` = Post.Prob
  ) |>
  select(Hypothesis, Mean, SE, `CrI*`, ER, `Posterior Prob`) |>
  mutate(Experiment = c("Experiment 1B", "")) |>
  relocate(Experiment, .before = everything())

```

```{r}
# Run hypotheses
a <- hypothesis(acc_c, "blur1 < 0") # high-blur  < (low-blur   + clear)/2
b <- hypothesis(acc_c, "blur2 = 0") # low-blur   < clear

# Round numeric outputs
round_hypothesis <- function(hyp) {
  hyp$hypothesis <- hyp$hypothesis |>
    mutate(across(where(is.numeric), round, 3))
  hyp
}

a <- round_hypothesis(a)
b <- round_hypothesis(b)

# Combine and format table
tab_acc1 <- bind_rows(a$hypothesis, b$hypothesis) |>
  mutate(
    Hypothesis = c(
      "High blur < (Low blur + Clear)",
      "Low blur < Clear"
    ),
    `CrI*` = str_glue("[{CI.Lower}, {CI.Upper}]")
  ) |>
  rename(
    Mean = Estimate,
    SE = Est.Error,
    ER = Evid.Ratio,
    `Posterior Prob` = Post.Prob
  ) |>
  select(Hypothesis, Mean, SE, `CrI*`, ER, `Posterior Prob`) |>
  mutate(Experiment = c("Experiment 1A", "")) |>
  relocate(Experiment, .before = everything())
```

```{r}
#| label: tbl-acc1A1B
#| tbl-cap: "Posterior distribution estimates for accuracy (Experiments 1A and 1B)"
#| apa-note: "CrI: 90% for one-sided tests and 95% for two-sided tests against 0. Posterior probability indicates the proportion of the posterior distribution that falls on one side of zero (either positive or negative), representing the probability that the effect is greater than or less than zero."
# Create the flextable

tabs1a1b <- rbind(tab_acc1, tab_acc2)


acc_summary1A1B <- flextable(tabs1a1b) |>
  theme_apa() |>
  width(j = 1, width = 2.5) |> # widen the Hypothesis column
  set_table_properties(layout = "autofit")

acc_summary1A1B
```

Model estimates can be found in @tbl-acc1A1B. High blur words had lower accuracy compared to clear and low-blur red words, $b$ = `r a$hypothesis$Estimate`, 90% CrI \[`r a$hypothesis$CI.Lower`, `r a$hypothesis$CI.Upper`\], ER = `r process_ER_column(a$hypothesis$Evid.Ratio)`. However, the evidence was weak for no significant differences in the identification accuracy between clear and low-blur red words, $b$ = `r b$hypothesis$Estimate`, 90% CrI \[`r b$hypothesis$CI.Lower`, `r b$hypothesis$CI.Upper`\], ER = `r process_ER_column(b$hypothesis$Evid.Ratio)`.

### RTs: Ex-Gaussian

```{r}
#load data from osf
rts <- read_csv("https://osf.io/xv5bd/download")
#rts <- read_csv("data/cleaned_context_rt.csv")
```

```{r}
blur_rt <- rts |>
  group_by(participant) |>
  dplyr::filter(corr == 1, lex == "m") #only include nonwords

blur_rt_new <- blur_rt |>
  dplyr::filter(rt >= .2 & rt <= 2.5) |> # remove high and low RTs
  mutate(rt_ms = rt * 1000)
```

The analysis of RTs (correct trials and words) is based on `r dim(blur_rt_new)[1]` data points, after removing fast and slow RTs (`r round(1-dim(blur_rt_new)[1]/dim(blur_rt)[1], 3)`).

```{r}
#| eval: false
bform_exg1 <- bf(
  rt ~ blur + (1 + blur | p | participant) + (1 + blur | i | string),
  sigma ~ blur + (1 + blur | p | participant) + (1 + blur | i | string),
  beta ~ blur + (1 + blur | p | participant) + (1 + blur | i | string)
)
```

```{r}
#| eval: false
prior_exp1 <- c(prior("normal(0,10)", class = "b", coef = ""))

fit_exg1A <- brm(
  bform_exg1,
  data = blur_rt_new,
  warmup = 1000,
  iter = 5000,
  prior = prior_exp1,
  family = three_param_exgauss,
  stanvars = three_param_exg_stanvars,
  init = 0,
  cores = 4,
  file = "mod_exgauss_1B",
  chains = 4,
  seed = 666,
  sample_prior = T,
  save_pars = save_pars(all = T),
  control = list(adapt_delta = 0.8),
  backend = "cmdstanr",
  threads = threading(2)
)
```

```{r}
fit_exg1A <- read_rds("https://osf.io/m4nv5/download") # expt1a ex gauss download
fit_exg1B <- read_rds("https://osf.io/ajwe4/download") # expt1b ex gauss download
```

```{r}
# Define hypothesis tests
a <- hypothesis(fit_exg1A, "blur1 > 0")
b <- hypothesis(fit_exg1A, "blur2 > 0")

c <- hypothesis(fit_exg1A, "sigma_blur1 > 0")
d <- hypothesis(fit_exg1A, "sigma_blur2 = 0")

e <- hypothesis(fit_exg1A, "beta_blur1 > 0")
f <- hypothesis(fit_exg1A, "beta_blur2 = 0")

# Round all numeric columns in each result
round_hypothesis <- function(hyp) {
  hyp$hypothesis <- hyp$hypothesis |>
    mutate(across(where(is.numeric), round, 3))
  hyp
}

a <- round_hypothesis(a)
b <- round_hypothesis(b)
c <- round_hypothesis(c)
d <- round_hypothesis(d)
e <- round_hypothesis(e)
f <- round_hypothesis(f)

# Combine into one table
tab_1a_ex <- bind_rows(
  a$hypothesis,
  b$hypothesis,
  c$hypothesis,
  d$hypothesis,
  e$hypothesis,
  f$hypothesis
) |>
  mutate(
    Parameter = c("Mu", "Mu", "Sigma", "Sigma", "Beta", "Beta"),
    Hypothesis = c(
      "High blur > (Low blur + Clear)",
      "Low blur > Clear",
      "High blur > (Low blur + Clear)",
      "Low blur = Clear",
      "High blur > (Low blur + Clear)",
      "Low blur = Clear"
    ),
    `CrI*` = str_glue("[{CI.Lower}, {CI.Upper}]")
  ) |>
  rename(
    Mean = Estimate,
    SE = Est.Error,
    ER = Evid.Ratio,
    `Posterior Prob` = Post.Prob
  ) |>
  select(Hypothesis, Parameter, Mean, SE, `CrI*`, ER, `Posterior Prob`) |>
  mutate(Experiment = c("Experiment 1A")) |>
  relocate(Experiment, .before = everything())

# Define hypothesis tests
a <- hypothesis(fit_exg1B, "blur1 > 0")
b <- hypothesis(fit_exg1B, "blur2 > 0")

c <- hypothesis(fit_exg1B, "sigma_blur1 > 0")
d <- hypothesis(fit_exg1B, "sigma_blur2 = 0")

e <- hypothesis(fit_exg1B, "beta_blur1 > 0")
f <- hypothesis(fit_exg1B, "beta_blur2 = 0")

a <- round_hypothesis(a)
b <- round_hypothesis(b)
c <- round_hypothesis(c)
d <- round_hypothesis(d)
e <- round_hypothesis(e)
f <- round_hypothesis(f)

# Combine into one table
tab_1b_ex <- bind_rows(
  a$hypothesis,
  b$hypothesis,
  c$hypothesis,
  d$hypothesis,
  e$hypothesis,
  f$hypothesis
) |>
  mutate(
    Parameter = c("Mu", "Mu", "Sigma", "Sigma", "Beta", "Beta"),
    Hypothesis = c(
      "High blur > (Low blur + Clear)",
      "Low blur > Clear",
      "High blur > (Low blur + Clear)",
      "Low blur = Clear",
      "High blur > (Low blur + Clear)",
      "Low blur = Clear"
    ),
    `CrI*` = str_glue("[{CI.Lower}, {CI.Upper}]")
  ) |>
  rename(
    Mean = Estimate,
    SE = Est.Error,
    ER = Evid.Ratio,
    `Posterior Prob` = Post.Prob
  ) |>
  select(Hypothesis, Parameter, Mean, SE, `CrI*`, ER, `Posterior Prob`) |>
  mutate(Experiment = c("Experiment 1B")) |>
  relocate(Experiment, .before = everything())

tabs <- bind_rows(tab_1a_ex, tab_1b_ex) |>
  mutate(
    Parameter = factor(Parameter, levels = c("Mu", "Sigma", "Beta"))
  ) |>
  arrange(Hypothesis, Parameter, Experiment)
```

```{r}
#| label: tbl-ex1A1B
#| tbl-cap: "Posterior distribution estimates for ex-gaussian distribution (Experiments 1A and 1B)"
#| apa-note: "CrI: 90% for one-sided tests and 95% for two-sided tests against 0. Posterior probability indicates the proportion of the posterior distribution that falls on one side of zero (either positive or negative), representing the probability that the effect is greater than or less than zero."

# Create the flextable

ft <- flextable(tabs) |>
  theme_apa() |>
  width(j = 1, width = 2.5) |> # widen the Hypothesis column
  set_table_properties(layout = "autofit")

ft


```

```{r}
# Define hypothesis tests
a <- hypothesis(fit_exg1A, "blur1 > 0")
b <- hypothesis(fit_exg1A, "blur2 > 0")

c <- hypothesis(fit_exg1A, "sigma_blur1 > 0")
d <- hypothesis(fit_exg1A, "sigma_blur2 = 0")

e <- hypothesis(fit_exg1A, "beta_blur1 > 0")
f <- hypothesis(fit_exg1A, "beta_blur2 = 0")

# Round all numeric columns in each result
round_hypothesis <- function(hyp) {
  hyp$hypothesis <- hyp$hypothesis |>
    mutate(across(where(is.numeric), round, 3))
  hyp
}

a <- round_hypothesis(a)
b <- round_hypothesis(b)
c <- round_hypothesis(c)
d <- round_hypothesis(d)
e <- round_hypothesis(e)
f <- round_hypothesis(f)

# Combine into one table
tab <- bind_rows(
  a$hypothesis,
  b$hypothesis,
  c$hypothesis,
  d$hypothesis,
  e$hypothesis,
  f$hypothesis
)
```

A visualization of how blurring affected processing during word recognition can be seen in the quantile and delta plots in A summary of the ex-Gaussion model can be found in @tbl-ex1A1B. Beginning with the $\mu$ parameter, there was greater shifting for high-blur red words compared to clear and low-blur red words, *b* = `r round(a$hypothesis$Estimate, 3)`, 90% CrI \[`r round(a$hypothesis$CI.Lower, 3)`, `r round(a$hypothesis$CI.Upper, 3)`\], ER = `r process_ER_column(a$hypothesis$Evid.Ratio)`. Low blurred compared to clear words showed greater shifting, *b* = `r round(b$hypothesis$Estimate, 3)`, 90% CrI \[`r round(b$hypothesis$CI.Lower, 3)`, `r round(b$hypothesis$CI.Upper, 3)`\], ER = `r process_ER_column(b$hypothesis$Evid.Ratio)`.

Analyses of the $\sigma$ and $\tau$ parameters yielded a similar pattern. Variance was higher for high-blur red words compared to clear and low-blur red words, *b* = `r round(c$hypothesis$Estimate, 3)`, 90% CrI \[`r round(c$hypothesis$CI.Lower, 3)`, `r round(c$hypothesis$CI.Upper, 3)`\], ER = `r process_ER_column(c$hypothesis$Evid.Ratio)`. There was strong evidence for no difference between low-blur red and clear words, *b* = `r round(d$hypothesis$Estimate, 3)`, 90% CrI \[`r round(d$hypothesis$CI.Lower, 3)`, `r round(d$hypothesis$CI.Upper, 3)`\], ER = `r process_ER_column(d$hypothesis$Evid.Ratio)`.

Finally, there was greater skewing for high-blur red words compared to clear and low-blur red words, *b* = `r round(e$hypothesis$Estimate, 3)`, 90% CrI \[`r round(e$hypothesis$CI.Lower, 3)`, `r round(e$hypothesis$CI.Upper, 3)`\], ER = `r round(e$hypothesis$Evid.Ratio, 3)`. There was strong evidence for no difference between low-blur red and clear words, *b* = `r round(f$hypothesis$Estimate, 3)`, 90% CrI \[`r round(f$hypothesis$CI.Lower, 3)`, `r round(f$hypothesis$CI.Upper, 3)`\], ER = `r process_ER_column(f$hypothesis$Evid.Ratio)`.

```{r}
#Delta plots (one per subject)
quibble <- function(x, q = seq(.1, .9, .2)) {
  tibble(x = quantile(x, q), q = q)
}

data.quantiles <- rts |>
  dplyr::filter(rt >= .2 | rt <= 2.5) |>
  dplyr::group_by(participant, blur, corr) |>
  dplyr::filter(lex == "m") |>
  dplyr::summarise(RT = list(quibble(rt, seq(.1, .9, .2)))) |>
  tidyr::unnest(RT)


data.delta <- data.quantiles |>
  dplyr::filter(corr == 1) |>
  dplyr::select(-corr) |>
  dplyr::group_by(participant, blur, q) |>
  dplyr::summarize(RT = mean(x))


#Delta plots (based on vincentiles)
vincentiles <- data.quantiles |>
  dplyr::filter(corr == 1) |>
  dplyr::select(-corr) |>
  dplyr::group_by(blur, q) |>
  dplyr::summarize(RT = mean(x))

v_1 = vincentiles |>
  dplyr::group_by(blur, q) |>
  dplyr::summarise(MRT = mean(RT))

v_1 <- v_1 |>
  mutate(
    blur = ifelse(
      blur == "HB",
      "High blur",
      ifelse(blur == "LB", "Low blur", "Clear")
    )
  )

v_1$blur <- factor(v_1$blur, level = c("High blur", "Low blur", "Clear"))

v_1 <- v_1 |>
  mutate(Experiment = "Experiment 1A")
```

```{r}
v_chb <- v_1 |>
  dplyr::filter(blur == "Clear" | blur == "High blur") |>
  dplyr::group_by(q) |>
  mutate(mean_rt = mean(MRT) * 1000) |>
  ungroup() |>
  select(-q) |>
  tidyr::pivot_wider(names_from = "blur", values_from = "MRT") |>
  mutate(diff = `High blur` * 1000 - Clear * 1000)

p1_dp <- ggplot(v_chb, aes(x = mean_rt, y = diff)) +
  geom_abline(intercept = 0, slope = 0) +
  geom_line(size = 1, colour = "black") +
  geom_point(size = 3, colour = "black") +
  theme(legend.position = "none") +
  theme_minimal(base_size = 16) +
  scale_y_continuous(breaks = seq(-10, 440, 50)) +
  scale_x_continuous(breaks = seq(600, 1300, 100)) +
  coord_cartesian(xlim = c(600, 1300), ylim = c(-10, 440)) +
  geom_label_repel(
    data = v_chb,
    aes(y = diff, label = round(diff, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5,
    size = 10
  ) +
  labs(
    title = "Clear vs. High blur",
    x = "",
    y = "Group differences",
    tag = "B"
  )
```

```{r}
v_clb <- v_1 |>
  dplyr::filter(blur == "Clear" | blur == "Low blur") |>
  dplyr::group_by(q) |>
  mutate(mean_rt = mean(MRT) * 1000) |>
  ungroup() |>
  select(-q) |>
  tidyr::pivot_wider(names_from = "blur", values_from = "MRT") |>
  mutate(diff = `Low blur` * 1000 - Clear * 1000)

p2_dp <- ggplot(v_clb, aes(x = mean_rt, y = diff)) +
  geom_abline(intercept = 0, slope = 0) +
  geom_line(size = 1, colour = "black") +
  geom_point(size = 3, colour = "black") +
  theme_minimal(base_size = 16) +
  theme(legend.position = "none") +
  scale_y_continuous(breaks = seq(-10, 440, 50)) +
  scale_x_continuous(breaks = seq(600, 1300, 100)) +
  coord_cartesian(xlim = c(600, 1300), ylim = c(-10, 440)) +
  geom_label_repel(
    data = v_clb,
    aes(y = diff, label = round(diff, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5,
    size = 10
  ) +
  labs(
    title = "Low blur vs. Clear",
    x = "Mean RT per quantile",
    y = ""
  )
```

```{r}
v_hlb <- v_1 |>
  dplyr::filter(blur == "High blur" | blur == "Low blur") |>
  dplyr::group_by(q) |>
  mutate(mean_rt = mean(MRT) * 1000) |>
  ungroup() |>
  select(-q) |>
  tidyr::pivot_wider(names_from = "blur", values_from = "MRT") |>
  mutate(diff = `High blur` * 1000 - `Low blur` * 1000)

p3_dp <- ggplot(v_hlb, aes(x = mean_rt, y = diff)) +
  geom_abline(intercept = 0, slope = 0) +
  geom_line(size = 1, colour = "black") +
  geom_point(size = 3, colour = "black") +
  theme_minimal(base_size = 16) +
  theme(legend.position = "none") +
  scale_y_continuous(breaks = seq(-10, 440, 50)) +
  scale_x_continuous(breaks = seq(600, 1300, 100)) +
  coord_cartesian(xlim = c(600, 1300), ylim = c(-10, 440)) +
  geom_label_repel(
    data = v_hlb,
    aes(y = diff, label = round(diff, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5,
    size = 10
  ) +
  labs(title = "High blur vs.  Low blur", x = "", y = "")
```

### Recognition Memory

```{r}
mem_c <- read_csv("https://osf.io/xjvc7/download")
#mem_c <- read_csv("data/blmm_sdt_context.csv")
```

```{r}
## Contrasts
#hypothesis
contrast_matrix <- matrix(
  c(
    -.5,
    -.5, # C
    .5,
    0, # HB
    -.5,
    .5
  ), # LB
  ncol = 2,
  byrow = TRUE
)

colnames(contrast_matrix) <- c("blur1", "blur2")
rownames(contrast_matrix) <- c("C", "HB", "LB")

# Apply to factor
mem_c$blur <- factor(mem_c$blur, levels = c("C", "HB", "LB"))
contrasts(mem_c$blur) <- contrast_matrix
```

```{r}
#| eval: false
#|
#priors for sdt model
sdt_priors <- c(set_prior("cauchy(0,0.35)", class = "b"))
```

```{r}
#| eval: false
#|
fit_mem_c <- brm(
  sayold ~
    isold *
      blur +
      (1 + isold * blur | participant) +
      (1 + isold * blur | string),
  data = mem_c,
  warmup = 1000,
  iter = 5000,
  chains = 4,
  init = 0,
  family = bernoulli(link = "probit"),
  cores = 4,
  control = list(adapt_delta = 0.9),
  prior = sdt_priors,
  sample_prior = T,
  seed = 666,
  file = "blmm_sdt_expt1",
  save_pars = save_pars(all = T),
  backend = "cmdstanr",
  threads = threading(2)
)
```

```{r}
fit_mem1 <- read_rds("https://osf.io/dbfwa/download")
#fit_mem1 <- read_rds("data/blmm_sdt_expt1a_priors_hblbc2.rds")
```

```{r}

a <- hypothesis(fit_mem1, "isold1:blur1  > 0")
b <- hypothesis(fit_mem1, "isold1:blur2 > 0")

a$hypothesis <- a$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
b$hypothesis <- b$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
```

#### Sensitivity

@fig-dprimeexp1A highlights $d'$ and $c$ means and comparisons across all groups. Sensitivity was higher for high-blur red words than for clear and low-blur red words, $\beta$ = `r a$hypothesis$Estimate`, 90% CrI \[`r a$hypothesis$CI.Lower`, `r a$hypothesis$CI.Upper`\], ER = `r process_ER_column(a$hypothesis$Evid.Ratio)`. The evidence for no difference in sensitivity between clear words and low-blur red words was strong, $\beta$ = `r b$hypothesis$Estimate`, 90% CrI \[`r b$hypothesis$CI.Lower`, `r b$hypothesis$CI.Upper`\], ER = `r process_ER_column(b$hypothesis$Evid.Ratio)`.

#### Exploratory Analyses: Bias

```{r}
a <- hypothesis(fit_mem1, "blur1 > 0")
b <- hypothesis(fit_mem1, "blur2 > 0")

a$hypothesis <- a$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
b$hypothesis <- b$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
```

Low blurred words had a bias towards more "old" responses compared to clear words, $\beta$ = `r b$hypothesis$Estimate`, 90% CrI \[`r b$hypothesis$CI.Lower`, `r b$hypothesis$CI.Upper`\], ER = `r process_ER_column(b$hypothesis$Evid.Ratio)`. High- blurred words showed a more liberal bias compared to clear and low-blur red words, $\beta$ = `r b$hypothesis$Estimate`, 90% CrI \[`r b$hypothesis$CI.Lower`, `r b$hypothesis$CI.Upper`\], ER = `r process_ER_column(b$hypothesis$Evid.Ratio)`.

```{r}
# (Negative) criteria
emm_m1_c1 <- emmeans(fit_mem1, ~blur) |>
  parameters::parameters(centrality = "mean")
# Differences in (negative) criteria
emm_m1_c2 <- emmeans(fit_mem1, ~blur) |>
  contrast("pairwise") |>
  parameters::parameters(centrality = "mean")

# Dprimes for three groups
emm_m1_d1 <- emmeans(fit_mem1, ~ isold + blur) |>
  contrast("revpairwise", by = "blur") |>
  parameters::parameters(centrality = "mean")
# Differences between groups
emm_m1_d2 <- emmeans(fit_mem1, ~ isold + blur) |>
  contrast(interaction = c("revpairwise", "pairwise")) |>
  parameters::parameters(centrality = "mean")
```

```{r}
#| label: fig-dprimeexp1A
#| fig-cap: Estimated posterior distributions for d-prime and criterion, and differences, with 95% CrIs
#| fig-width: 12
#| fig-height: 8

emm_m1_c1 <- emmeans(fit_mem1, ~blur)

emm_m1_c2 <- emmeans(fit_mem1, ~blur) |>
  contrast("pairwise")

# Dprimes for three groups
emm_m1_d1 <- emmeans(fit_mem1, ~ isold + blur) |>
  contrast("revpairwise", by = "blur")
# Differences between groups
emm_m1_d2 <- emmeans(fit_mem1, ~ isold + blur) |>
  contrast(interaction = c("revpairwise", "pairwise"))

tmp <- bind_rows(
  bind_rows(
    gather_emmeans_draws(emm_m1_d1) |>
      group_by(blur) |>
      select(-contrast),
    gather_emmeans_draws(emm_m1_d2) |>
      rename(
        blur = blur_pairwise
      ) |>
      group_by(blur) |>
      select(-isold_revpairwise)
  ),
  bind_rows(
    gather_emmeans_draws(emm_m1_c1),
    gather_emmeans_draws(emm_m1_c2) |>
      rename(
        blur = contrast
      )
  ),
  .id = "Parameter"
) |>
  mutate(Parameter = factor(Parameter, labels = c("d-prime", "Criterion"))) |>
  mutate(
    t = if_else(str_detect(blur, " - "), "Differences", "Group means") |>
      fct_inorder(),
    blur = fct_inorder(blur)
  )

tmp |>
  ungroup() |>
  mutate(.value = if_else(Parameter == "Criterion", .value * -1, .value)) |>
  mutate(Parameter = fct_rev(Parameter)) |>
  mutate(
    blur = case_when(
      blur == "C" ~ "Clear",
      blur == "C - HB" ~ "Clear - High blur",
      blur == "HB" ~ "High blur",
      blur == "LB" ~ "Low blur",
      blur == "C - LB" ~ "Clear - Low blur",
      TRUE ~ "High blur - Low blur"
    )
  ) |>
  ggplot(aes(blur, .value)) +
  labs(
    x = "Blurring Level (or difference)",
    y = "Parameter value",
  ) +
  stat_halfeye(colour = "black", .width = c(0.95), point_interval = "mean_qi") +
  facet_grid(Parameter ~ t, scales = "free") +
  geom_hline(yintercept = 0, linewidth = .25) +
  theme_minimal(base_size = 16) +
  theme(
    strip.background = element_rect(fill = "black", color = "black"),
    strip.text = element_text(color = "white", face = "bold")
  )
```

## Discussion

**Experiment 1A successfully replicated the pattern of results found in @rosner2015. Specifically, we found high-blur red words had lower accuracy than clear and low-blur red words, but had better memory. Adding to these results, we used the ex-Guassin model model to gain further insights into the mechanisms underlying the perceptual disfluency effect. Descriptively, high-blur red words induced a more pronounced shift in the RT distribution (**$\mu$**) and exhibited a higher degree of skew (**$\beta$**) compared to clear and low-blur red words. However, low-blur red words did not differ compared to clear words on** $\mu$ **or** $\beta$**. These patterns can be clearly seen in the quantile and delta plots in @fig-deltaquant1A1B.**

**This pattern argues against a purely metacognitive account [e.g., @pieger2016] and instead supports explanations that emphasize a combination of early and higher-level processing [e.g., stage-specific; @ptok2019], or compensatory processing [@mulligan1996]. At the same time, considerable debate remains regarding the appropriateness of the ex-Gaussian distribution for drawing inferences about latent cognitive processes [@fitousi2020; @matzke2009].**

**Unlike the ex-Gaussian distribution, which makes little theoretical assumptions regarding process, the drift diffusion model - DDM [see @ratcliff2016, for a comprehensive introduction] is a process-model, and it's parameters can be linked to latent cognitive constructs [@gomez2013]. The DDM is a popular computational model commonly used in binary speeded decision tasks such as the lexical decision task (LDT). The DDM model assumes a decision is a cumulative process that begins at stimulus onset and ends once a noisy accumulation of evidence has reached a decision threshold.The DDM has led to important insights into cognition in a wide range of choice tasks, including perceptual-, memory-, and value-based decisions [@myers2022].**

**In the DDM, RTs are decomposed into several parameters that represent distinct cognitive processes. The most relevant to our purposes here are the drift rate (**$v$**) and non-decision time (ndt;** $T_{er}$**) parameters. Drift rate (**$v$**) represents the rate at which evidence is accumulated towards a decision boundary. In essence, it is a measure of how quickly information is processed to make a decision. A higher (more positive)** $v$ **indicates a steeper slope, meaning that evidence is accumulated more quickly, leading to faster decisions. Conversely, a lower** $v$ **indicates a shallower slope, meaning that evidence is accumulated more slowly. Drift rate is closely linked to the decision-making process itself and serves as an index of global processing demands imposed by factors such as task difficulty, memory load, or other concurrent cognitive demands—particularly when these processes compete for the same cognitive resources [@boag2019]. Additionally, drift rates have been implicated as a key mechanism of reactive inhibitory control [@braver2012], where critical events (e.g., working memory updates or task switches) trigger inhibition of prepotent response drift rates [@boag2019; @boag2019a].**

**The** $T_{er}$ **parameter represents the time taken for processes other than the decision-making itself. This includes early sensory processing (like visual or auditory processing of the stimulus) and late motor processes (like executing the response). The DDM has been shown to be a valuable tool for studying the effects of different experimental manipulations on cognitive processes in visual word recognition. For example, @gomez2014 demonstrated certain manipulations can deferentially affect specific parameters of the model. For instance, manipulating the orientation of words (rotating them by 0, 90, or 180 degrees) affected the** $T_{er}$ **component, but not** $v$ **component. In contrast, word frequency (high-frequency words vs. low-frequency words) primarily influenced both the drift rate and non-decision time. These findings highlight the sensitivity of the DDM in identifying and differentiating the impact of various stimulus manipulations on different cognitive processes involved in decision-making.**

**We preregistered DDM analyses and present the model results in the Appendix to enhance readability. Overall, we found high-blur red words impacted both an early, non-decision, component evinced by higher** $T_{er}$ **and a later more analytic, component evinced by a lower** $v$ **than clear or low-blur red words. On the other hand, low-blur red words only affected** $T_{er}$**.**

**Herein, we present evidence that different levels of disfluency can influence distinct stages of encoding, potentially contributing to the presence or absence of a mnemonic effect for perceptually blurred stimuli. Unlike most studies that commonly employ a single level of disfluency, our study incorporated two levels of disfluency. The results indicate that a subtle manipulation such as low-blur primarily affects early processing stages, whereas a more pronounced perceptual manipulation (i.e., high-blur ) impacts both early and late processing stages. Regarding recognition memory, high-blur red stimuli were better recognized compared to low-blur red and clear words. This suggests that in order to observe a perceptual disfluency effect, the perceptual manipulation must be sufficiently disfluent to do so and tap later stages of encoding.**

**Given the important theoretical implications of these findings, Experiment 1B served as a conceptual replication. Due to the bias observed in the recognition memory test (i.e., low-blur red words were responded to more liberally), we do not present old and new items as blurred at test, instead all of the words were presented in a clear, different, font at test.**

# Experiment 1B: No Context Reinstatement

## Method

### Transparency and Openness

This study was not preregistered. All raw and summary data, materials, and R scripts for pre-processing, analysis, and plotting for Experiment 1B can be found at https://osf.io/6sy7k/.

### Participants

**All participants were recruited through the Rutgers University subject pool (SONA system). We preregistered a sample size of 216 participants. A total of 282 participants completed the study. Per our exclusion criteria, 5 participants were removed for completing the experiment more than once, 19 were removed for accuracy below 80%, and 1 was removed for being under 18. No participants were excluded for being non-native English speakers. This resulted in 258 eligible participants. To account for oversampling and to ensure equal numbers across lists, we randomly selected 36 participants from each list, yielding a final analyzed sample of 216 participants.**

**The study protocol was reviewed and approved by the Rutgers University Institutional Review Board.**

### Apparatus, Stimuli, Design, Procedure, and Analysis

Similar to Experiment 1A, the experiment was run using PsychoPy [@peirce2019] and hosted on Pavlovia (www.pavlovia.org). You can see an example of the experiment by navigating to this website: https://run.pavlovia.org/Jgeller112/ldt_dd_l1_jol.

We used the same stimuli from Experiment 1A. The main difference between Experiments 1A and 1B was all items were presented in a clear, Arial font. To make it more similar to Experiment 1A each set of words presented as clear, low-blur , and high-blur at study were yoked to a set of new words that were counterbalanced across lists. Therefore, instead of there being one false alarm rate there were 3, one for each blurring level. This ensured each word was compared to studied clear, studied high-blur red, and studied low-blur red words. The same model specifications and analyses used in Experiment 1A were used in Experiment 1B.

## Results

### Accuracy

```{r}
#| label: acc_expt1b
# get data from osf
# https://osf.io/excgd/download
blur_acc <- read_csv("https://osf.io/excgd/download") |>
  dplyr::filter(lex == "m")

blur_acc_new <- blur_acc |>
  dplyr::filter(rt >= .2 & rt <= 2.5)
```

The analysis of accuracy is based on `r dim(blur_acc_new)[1]` data points. after removing fast (\< .2 s) and slow (\> 2.5 s) RTs (`r round(1-dim(blur_acc_new)[1]/dim(blur_acc)[1], 2)`).

```{r}
# Create custom contrast matrix manually
contrast_matrix <- matrix(
  c(
    -.5,
    -.5, # C
    .5,
    0, # HB
    -.5,
    .5
  ), # LB
  ncol = 2,
  byrow = TRUE
)

blur_acc_new$blur <- as.factor(blur_acc_new$blur)

# Assign to factor
contrasts(blur_acc_new$blur) <- contrast_matrix
```

```{r}
#| eval: false

#weak prior
prior_exp1 <- c(set_prior("cauchy(0,.35)", class = "b"))

#fit model
fit_acc_weak <- brm(
  corr ~ blur + (1 + blur | participant) + (1 + blur | string),
  data = blur_acc_new,
  warmup = 1000,
  iter = 5000,
  chains = 4,
  init = 0,
  family = bernoulli(),
  cores = 4,
  prior = prior_exp1,
  control = list(adapt_delta = 0.9),
  backend = "cmdstanr",
  save_pars = save_pars(all = T),
  sample_prior = T,
  threads = threading(4),
  file = "fit_acc_weak_nocontext"
)
```

```{r}
# get file from osf
fit_acc_noc <- read_rds("https://osf.io/p9xat/download")
#fit_acc_noc <- read_rds("data/fit_acc_weak_nocontext.rds")
```

```{r}
acc_means <- emmeans(fit_acc_noc, specs = "blur", type = "response")
```

```{r}
# Run hypotheses
a <- hypothesis(fit_acc_noc, "blur1 < 0") # high-blur  < (low-blur   + clear)/2
b <- hypothesis(fit_acc_noc, "blur2 = 0") # low-blur   < clear

# Round numeric outputs
round_hypothesis <- function(hyp) {
  hyp$hypothesis <- hyp$hypothesis |>
    mutate(across(where(is.numeric), round, 3))
  hyp
}

a <- round_hypothesis(a)
b <- round_hypothesis(b)

# Combine and format table
tab_acc2 <- bind_rows(a$hypothesis, b$hypothesis) |>
  mutate(
    Hypothesis = c(
      "High blur < (Low blur + Clear)",
      "Low blur = Clear"
    ),
    `CrI*` = str_glue("[{CI.Lower}, {CI.Upper}]")
  ) |>
  rename(
    Mean = Estimate,
    SE = Est.Error,
    ER = Evid.Ratio,
    `Posterior Prob` = Post.Prob
  ) |>
  select(Hypothesis, Mean, SE, `CrI*`, ER, `Posterior Prob`) |>
  mutate(Experiment = c("Experiment 1B", "")) |>
  relocate(Experiment, .before = everything())

```

A summary of posterior estimates are located in @tbl-acc1A1B. High blur words had lower accuracy compared to clear and low-blur red words, $b$ = `r a$hypothesis$Estimate`, 90% CrI \[`r a$hypothesis$CI.Lower`, `r a$hypothesis$CI.Upper`\], ER = `r process_ER_column(a$hypothesis$Evid.Ratio)`. However, the evidence was weak for no significant difference in the identification accuracy between clear and low-blur red words, $b$ = `r b$hypothesis$Estimate`, 90% CrI \[`r b$hypothesis$CI.Lower`, `r b$hypothesis$CI.Upper`\], ER = `r process_ER_column(b$hypothesis$Evid.Ratio)`.

### RTs: Ex-Gaussian

```{r}
#load data from osf
rts <- read_csv("https://osf.io/excgd/download")
#rts <- read_csv("data/cleaned_nocontext_rt.csv")
```

```{r}
blur_rt <- rts |>
  group_by(participant) |>
  dplyr::filter(corr == 1, lex == "m") #only include nonwords

blur_rt_new <- blur_rt |>
  dplyr::filter(rt >= .2 & rt <= 2.5) |>
  mutate(rt_ms = rt * 1000)
```

The analysis of RTs (correct trials and word stimuli) is based on `r dim(blur_rt_new)[1]` data points, after removing fast (\< .2 s) and slow (\> 2.5 s) RTs (`r round(1-dim(blur_rt_new)[1]/dim(blur_rt)[1], 3)`)

```{r}
#hypothesis
blurC <- hypr(HB ~ C, HB ~ LB, levels = c("C", "HB", "LB"))

#set contrasts in df
blur_rt$blur <- as.factor(blur_rt$blur)

contrasts(blur_rt$blur) <- contr.hypothesis(blurC)
```

```{r}
#| eval: false

bform_exg1B <- bf(
  rt ~ 0 + blur + (1 + blur | p | participant) + (1 + blur | i | string),
  sigma ~ 0 + blur + (1 + blur | p | participant) + (1 + blur | i | string),
  beta ~ 0 + blur + (1 + blur | p | participant) + (1 + blur | i | string)
)
```

```{r}
#| eval: false
#|
prior1B <- c(prior("normal(0,10)", class = "b", coef = ""))

fit_exg1B <- brm(
  bform_exg1B,
  data = blur_rt_new,
  warmup = 1000,
  iter = 5000,
  prior = prior1B,
  family = three_param_exgauss,
  stanvars = three_param_exg_stanvars,
  init = 0,
  cores = 4,
  file = "mod_exgauss_1B",
  chains = 4,
  seed = 666,
  sample_prior = T,
  save_pars = save_pars(all = T),
  control = list(adapt_delta = 0.8),
  backend = "cmdstanr",
  threads = threading(2)
)
```

```{r}
fit_exg1B <- read_rds("https://osf.io/ajwe4/download")
```

```{r}

# Define hypothesis tests
a <- hypothesis(fit_exg1B, "blur1 > 0")
b <- hypothesis(fit_exg1B, "blur2 > 0")

c <- hypothesis(fit_exg1B, "sigma_blur1 > 0")
d <- hypothesis(fit_exg1B, "sigma_blur2 = 0")

e <- hypothesis(fit_exg1B, "beta_blur1 > 0")
f <- hypothesis(fit_exg1B, "beta_blur2 = 0")

# Round all numeric columns in each result
round_hypothesis <- function(hyp) {
  hyp$hypothesis <- hyp$hypothesis |>
    mutate(across(where(is.numeric), round, 3))
  hyp
}

a <- round_hypothesis(a)
b <- round_hypothesis(b)
c <- round_hypothesis(c)
d <- round_hypothesis(d)
e <- round_hypothesis(e)
f <- round_hypothesis(f)

# Combine into one table
tab <- bind_rows(
  a$hypothesis,
  b$hypothesis,
  c$hypothesis,
  d$hypothesis,
  e$hypothesis,
  f$hypothesis
)
```

A visualization of how blurring affected processing during word recognition can be seen in the quantile and delta plots in. A summary of the results can be found in @tbl-ex1A1B. Beginning with the $\mu$ parameter, there was greater shifting for high-blur red words compared to clear and low-blur red words, *b* = `r round(a$hypothesis$Estimate, 3)`, 90% CrI \[`r round(a$hypothesis$CI.Lower, 3)`, `r round(a$hypothesis$CI.Upper, 3)`\], ER = `r process_ER_column(a$hypothesis$Evid.Ratio)`. Low blurred words had greater shifting compared to clear words, *b* = `r round(b$hypothesis$Estimate, 3)`, 90% CrI \[`r round(b$hypothesis$CI.Lower, 3)`, `r round(b$hypothesis$CI.Upper, 3)`\], ER = `r process_ER_column(c$hypothesis$Evid.Ratio)`. Analyses of the $\sigma$ parameter yielded a similar pattern. Variance was higher for high-blur red words compared to clear and low-blur red words, *b* = `r round(c$hypothesis$Estimate, 3)`, 90% CrI \[`r round(c$hypothesis$CI.Lower, 3)`, `r round(c$hypothesis$CI.Upper, 3)`\], ER = `r process_ER_column(c$hypothesis$Evid.Ratio)`. There was no evidence of a difference in variance between low-blur red and clear words,*b* = `r round(d$hypothesis$Estimate, 3)`, 90% CrI \[`r round(d$hypothesis$CI.Lower, 3)`, `r round(d$hypothesis$CI.Upper, 3)`\], ER = `r process_ER_column(d$hypothesis$Evid.Ratio)` Finally, there was greater skewing for high-blur red words compared to clear and low-blur red words, *b* = `r round(e$hypothesis$Estimate, 3)`, 90% CrI \[`r round(e$hypothesis$CI.Lower, 3)`, `r round(e$hypothesis$CI.Upper, 3)`\], ER = `r round(e$hypothesis$Evid.Ratio, 3)`. There was no evidence of a difference in variance between low-blur red and clear words,*b* = `r round(f$hypothesis$Estimate, 3)`, 90% CrI \[`r round(f$hypothesis$CI.Lower, 3)`, `r round(f$hypothesis$CI.Upper, 3)`\], ER = `r process_ER_column(f$hypothesis$Evid.Ratio)`.

```{r}
#Delta plots (one per subject)
quibble <- function(x, q = seq(.1, .9, .2)) {
  tibble(x = quantile(x, q), q = q)
}

data.quantiles <- rts |>
  dplyr::filter(rt >= .2 | rt <= 2.5) |>
  dplyr::group_by(participant, blur, corr) |>
  dplyr::filter(lex == "m") |>
  dplyr::summarise(RT = list(quibble(rt, seq(.1, .9, .2)))) |>
  tidyr::unnest(RT)

data.delta <- data.quantiles |>
  dplyr::filter(corr == 1) |>
  dplyr::select(-corr) |>
  dplyr::group_by(participant, blur, q) |>
  dplyr::summarize(RT = mean(x))

#Delta plots (based on vincentiles)
vincentiles <- data.quantiles |>
  dplyr::filter(corr == 1) |>
  dplyr::select(-corr) |>
  dplyr::group_by(blur, q) |>
  dplyr::summarize(RT = mean(x))

v_2 = vincentiles |>
  dplyr::group_by(blur, q) |>
  dplyr::summarise(MRT = mean(RT))

v_2 <- v_2 |>
  mutate(
    blur = ifelse(
      blur == "HB",
      "High blur",
      ifelse(blur == "LB", "Low blur", "Clear")
    )
  )

v_2 <- v_2 |>
  mutate(
    blur = factor(blur, level = c("High blur", "Low blur", "Clear")),
    Experiment = "Experiment 1B"
  )

v_12 <- bind_rows(v_1, v_2)

p_12 <- ggplot(v_12, aes(x = q, y = MRT * 1000, colour = blur, group = blur)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  scale_y_continuous(breaks = seq(500, 1600, 100)) +
  theme(legend.title = element_blank()) +
  coord_cartesian(ylim = c(500, 1600)) +
  scale_x_continuous(breaks = seq(.1, .9, .2)) +
  geom_label_repel(
    data = v_12,
    aes(x = q, y = MRT * 1000, label = round(MRT * 1000, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5,
    size = 10
  ) +
  facet_grid(~Experiment) +
  labs(
    x = "Quantiles",
    y = "Response latencies in ms",
    tag = "A",
    colour = 'Blur Condition'
  ) + # Optional tag for labeling
  theme_minimal(base_size = 16) +
  theme(legend.position = "bottom") +
  ggokabeito::scale_colour_okabe_ito()
```

```{r}
v_chb <- v_2 |>
  dplyr::filter(blur == "Clear" | blur == "High blur") |>
  dplyr::group_by(q) |>
  mutate(mean_rt = mean(MRT) * 1000) |>
  ungroup() |>
  select(-q) |>
  tidyr::pivot_wider(names_from = "blur", values_from = "MRT") |>
  mutate(diff = `High blur` * 1000 - Clear * 1000)

p1_dp2 <- ggplot(v_chb, aes(x = mean_rt, y = diff)) +
  geom_abline(intercept = 0, slope = 0) +
  geom_line(size = 1, colour = "black") +
  geom_point(size = 3, colour = "black") +
  theme(legend.position = "none") +
  theme_minimal(base_size = 16) +
  scale_y_continuous(breaks = seq(10, 440, 50)) +
  coord_cartesian(xlim = c(600, 1300), ylim = c(10, 440)) +
  scale_x_continuous(breaks = seq(600, 1300, 100)) +
  geom_label_repel(
    data = v_chb,
    aes(y = diff, label = round(diff, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5,
    size = 10
  ) +
  labs(
    title = "High blur vs. Clear",
    x = "",
    y = "Group differences",
    tag = "C"
  )
```

```{r}
v_clb <- v_2 |>
  dplyr::filter(blur == "Clear" | blur == "Low blur") |>
  dplyr::group_by(q) |>
  mutate(mean_rt = mean(MRT) * 1000) |>
  ungroup() |>
  select(-q) |>
  tidyr::pivot_wider(names_from = "blur", values_from = "MRT") |>
  mutate(diff = `Low blur` * 1000 - Clear * 1000)

p2_dp2 <- ggplot(v_clb, aes(x = mean_rt, y = diff)) +
  geom_abline(intercept = 0, slope = 0) +
  geom_line(size = 1, colour = "black") +
  geom_point(size = 3, colour = "black") +
  theme_minimal(base_size = 16) +
  theme(legend.position = "none") +
  scale_y_continuous(breaks = seq(10, 440, 50)) +
  scale_x_continuous(breaks = seq(600, 1300, 100)) +
  coord_cartesian(xlim = c(600, 1300), ylim = c(10, 440)) +
  geom_label_repel(
    data = v_clb,
    aes(y = diff, label = round(diff, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5,
    size = 10
  ) +
  labs(
    title = "Low blur vs. Clear",
    x = "Mean RT per quantile",
    y = ""
  )
```

```{r}
v_hlb <- v_2 |>
  dplyr::filter(blur == "High blur" | blur == "Low blur") |>
  dplyr::group_by(q) |>
  mutate(mean_rt = mean(MRT) * 1000) |>
  ungroup() |>
  select(-q) |>
  tidyr::pivot_wider(names_from = "blur", values_from = "MRT") |>
  mutate(diff = `High blur` * 1000 - `Low blur` * 1000)

p3_dp2 <- ggplot(v_hlb, aes(x = mean_rt, y = diff)) +
  geom_abline(intercept = 0, slope = 0) +
  geom_line(size = 1, colour = "black") +
  geom_point(size = 3, colour = "black") +
  theme_minimal(base_size = 16) +
  theme(legend.position = "none") +
  scale_y_continuous(breaks = seq(10, 440, 50)) +
  scale_x_continuous(breaks = seq(600, 1300, 100)) +
  coord_cartesian(xlim = c(600, 1300), ylim = c(10, 440)) +
  geom_label_repel(
    data = v_hlb,
    aes(y = diff, label = round(diff, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5,
    size = 10
  ) +
  labs(title = "High blur vs. Low blur", x = "", y = "")
```

```{r}
#| label: fig-deltaquant1A1B
#| fig-cap: "Quantile plots for each blur condition in Experiments 1A and 1B (A) and Delta plots depicting the magnitude of the effect for hypotheses of interest over time in Experiments 1A (B) and 1B (C). Each dot represents the mean RT at the .1, .3, .5, .7 and .9 quantiles."
#| fig-width: 20
#| fig-height: 12

delta_comb1a = (p1_dp + p2_dp + p3_dp)

delta_comb1b = (p1_dp2 + p2_dp2 + p3_dp2)

combined_plot <- p_12 / delta_comb1a / delta_comb1b

combined_plot

```

### Recognition Memory

```{r}
mem_nc <- read_csv("https://osf.io/jw2gx/download")
#mem_nc <- read_csv("data/cond_blmm_sdt_contextnot.csv")
```

```{r}
## Contrasts
#hypothesis

contrast_matrix <- matrix(
  c(
    -0.5,
    -.5, # C
    0.5,
    0, # HB
    -0.5,
    0.5
  ), # LB
  ncol = 2,
  byrow = TRUE
)

# Apply to factor
mem_nc$blur <- factor(mem_nc$blur, levels = c("C", "HB", "LB"))
contrasts(mem_nc$blur) <- contrast_matrix

mem_nc$isold <- factor(mem_nc$isold, levels = c(0, 1)) # ensure proper level order
contrasts(mem_nc$isold) <- matrix(c(-0.5, 0.5), ncol = 1)

# Apply to factor
mem_nc$blur <- factor(mem_nc$blur, levels = c("C", "HB", "LB"))
contrasts(mem_nc$blur) <- contrast_matrix

mem_nc$isold <- factor(mem_nc$isold, levels = c(0, 1)) # ensure proper level order
contrasts(mem_nc$isold) <- matrix(c(-0.5, 0.5), ncol = 1)
```

```{r}
#| eval: false
#|

# weak prior
sdt_priors <- c(set_prior("cauchy(0,.35)", class = "b"))

fit_mem_nc <- brm(
  sayold ~
    isold *
      blur +
      (1 + isold * blur | participant) +
      (1 + isold * blur | string),
  data = mem_nc,
  warmup = 1000,
  iter = 5000,
  chains = 4,
  init = 0,
  family = bernoulli(link = "probit"),
  cores = 4,
  control = list(adapt_delta = 0.9),
  prior = sdt_priors,
  seed = 666,
  sample_prior = T,
  file = "blmm_sdt_noc",
  save_pars = save_pars(all = T),
  backend = "cmdstanr",
  threads = threading(2)
)
```

```{r}
fit_mem_noc <- read_rds("https://osf.io/yfzke/download")
#fit_mem_noc <- read_rds("data/blmm_sdt_nc_hblbc.rds")
```

```{r}
#HB > C
a <- hypothesis(fit_mem_noc, "isold1:blur1 > 0")
b <- hypothesis(fit_mem_noc, "isold1:blur2 = 0")

a$hypothesis <- a$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
b$hypothesis <- b$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
c$hypothesis <- c$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
```

#### Sensitivity

@fig-dprimeexp1B highlights $d'$ and $c$ means and comparisons across all groups. Sensitivity was higher for high-blur red words than for clear and low-blur red words, $\beta$ = `r a$hypothesis$Estimate`, 90% CrI \[`r a$hypothesis$CI.Lower`, `r a$hypothesis$CI.Upper`\], ER = `r process_ER_column(a$hypothesis$Evid.Ratio)`. The evidence for no difference in sensitivity between clear words and low-blur red words was strong, $\beta$ = `r b$hypothesis$Estimate`, 90% CrI \[`r b$hypothesis$CI.Lower`, `r b$hypothesis$CI.Upper`\], ER = `r process_ER_column(b$hypothesis$Evid.Ratio)`.

```{r}
# (Negative) criteria
emm_m1_c1 <- emmeans(fit_mem_noc, ~blur) |>
  parameters::parameters(centrality = "mean")
# Differences in (negative) criteria
emm_m1_c2 <- emmeans(fit_mem_noc, ~blur) |>
  contrast("pairwise") |>
  parameters::parameters(centrality = "mean")

# Dprimes for three groups
emm_m1_d1 <- emmeans(fit_mem_noc, ~ isold + blur) |>
  contrast("revpairwise", by = "blur") |>
  parameters::parameters(centrality = "mean")
# Differences between groups
emm_m1_d2 <- emmeans(fit_mem_noc, ~ isold + blur) |>
  contrast(interaction = c("revpairwise", "pairwise")) |>
  parameters::parameters(centrality = "mean")
```

```{r}
#| label: fig-dprimeexp1B
#| fig-cap: Estimated posterior distributions (mean) for d-prime and criterion, and differences, with 95%  CrIs
#| fig-width: 12
#| fig-height: 8

emm_m1_c1 <- emmeans(fit_mem_noc, ~blur)

emm_m1_c2 <- emmeans(fit_mem_noc, ~blur) |>
  contrast("pairwise")

# Dprimes for three groups
emm_m1_d1 <- emmeans(fit_mem_noc, ~ isold + blur) |>
  contrast("revpairwise", by = "blur")
# Differences between groups
emm_m1_d2 <- emmeans(fit_mem_noc, ~ isold + blur) |>
  contrast(interaction = c("revpairwise", "pairwise"))

tmp <- bind_rows(
  bind_rows(
    gather_emmeans_draws(emm_m1_d1) |>
      group_by(blur) |>
      select(-contrast),
    gather_emmeans_draws(emm_m1_d2) |>
      rename(
        blur = blur_pairwise
      ) |>
      group_by(blur) |>
      select(-isold_revpairwise)
  ),
  bind_rows(
    gather_emmeans_draws(emm_m1_c1),
    gather_emmeans_draws(emm_m1_c2) |>
      rename(
        blur = contrast
      )
  ),
  .id = "Parameter"
) |>
  mutate(Parameter = factor(Parameter, labels = c("d-prime", "Criterion"))) |>
  mutate(
    t = if_else(str_detect(blur, " - "), "Differences", "Group means") |>
      fct_inorder(),
    blur = fct_inorder(blur)
  )

tmp |>
  ungroup() |>
  mutate(.value = if_else(Parameter == "Criterion", .value * -1, .value)) |>
  mutate(Parameter = fct_rev(Parameter)) |>
  mutate(
    blur = case_when(
      blur == "C" ~ "Clear",
      blur == "C - HB" ~ "Clear - High blur",
      blur == "HB" ~ "High blur",
      blur == "LB" ~ "Low blur",
      blur == "C - LB" ~ "Clear - Low blur",
      TRUE ~ "High blur - Low blur"
    )
  ) |>
  ggplot(aes(blur, .value)) +
  labs(
    x = "Blurring Level (or difference)",
    y = "Parameter value",
  ) +
  stat_halfeye(colour = "black", .width = c(0.95), point_interval = "mean_qi") +
  facet_grid(Parameter ~ t, scales = "free") +
  geom_hline(yintercept = 0, linewidth = .25) +
  theme_minimal(base_size = 16) +
  theme(
    strip.background = element_rect(fill = "black", color = "black"),
    strip.text = element_text(color = "white", face = "bold")
  )
```

## Discussion

**We replicated all findings of Experiment 1A in a design where blurring was not reinstated at test. In addition, DDM fits to both RTs and accuracy produced similar results (see Appendix).**

# Experiment 2: Semantic Categorization

**In Experiments 1A and 1B, we used the ex-Gaussian distribution to examine how visual blurring influences encoding and recognition memory. High-blurred words affected both early and late stages of processing, as indicated by shifts and increased skew in the response time distribution. By contrast, low-blurred words, relative to clear words, appeared to influence only early-stage processing, primarily through distributional shifts.**

**Recognition memory paralleled this dissociation: sensitivity was greater for high-blurred words than for either clear or low-blurred words. These findings support a stage-specific account of the disfluency effect, suggesting that blurring influences not only early perceptual encoding but also later, higher-level processes involved in word recognition and memory.**

**To test this account more directly, we next examined whether blurring interacts with a higher-level linguistic variable that is known to affect both early and late stages of word recognition: word frequency. Numerous models propose that lexical access varies systematically with frequency [@coltheart2001; @mcclelland1981]. Distributional analyses show that low-frequency words produce both larger shifts and greater skew than high-frequency words [@andrews2001; @balota1999; @plourde1997; @staub2010; @yap2007; but see @gomez2014]. If blurring indeed extends to higher-level stages of processing, then the combined effects of blurring and word frequency should provide a direct test of the stage-specific account.**

**In recognition memory, low-frequency words are generally remembered better than high-frequency words [@glanzer1985]. This advantage has been attributed to the increased cognitive effort or attentional resources required to encode low-frequency items [@diana2006], a view referred to as the elevated attention hypothesis [@malmberg2003; but see @pazzaglia2014 for alternative perspectives]. Critically, in tasks such as semantic categorization and pronunciation, word frequency has been shown to interact with stimulus degradation, yielding over-additive effects [@yap2007]. According to the logic of additive factors [@sternberg1969], such interactions suggest that the manipulated variables impact a shared processing stage. This interaction likely arises because perceptual disfluency disrupts early visual processing and lexical identification, thereby amplifying the frequency effect. Indeed, prior work has documented magnified word frequency effects under perceptual disfluency, including with handwritten cursive text [@barnhart2010; @perea2016] and rotated letter forms [@fernández-lópez2022].**

**In Experiment 2, we manipulated word frequency (high vs. low) and visual blur (clear, low, high) within a semantic categorization task, followed by a surprise recognition test. The stage-specific account predicts that disfluency effects extend beyond perceptual encoding to influence later stages of processing. Thus, combining perceptual disfluency and lexical difficulty may particularly engage extra- or post-lexical mechanisms—especially for blurred, low-frequency words.**

**Individually, each factor may be resolved through more effortful lexical access (reflected in changes to** $\mu$**). However, their combination could exceed lexical-level compensation, thereby recruiting additional control or decision-related processes. This account predicts an interaction on** $\beta$**, with blurred, low-frequency words producing especially long response-time tails, consistent with increased late-stage demands. Crucially, such late-stage engagement does not guarantee a memory advantage: when both perceptual and lexical demands are high, limited resources may be overtaxed, reducing or eliminating downstream mnemonic benefits.**

**With respect to memory, the stage-specific account further predicts that disfluency benefits are selective. Low-frequency words already attract increased attention during encoding [e.g., @kuchinke2007], making additional boosts from disfluency redundant. High-frequency words, by contrast, are typically processed more automatically and may gain more from disfluency manipulations that increase attention and depth of encoding. Supporting this view, prior work shows that disfluency effects on memory are strongest under otherwise fluent conditions [@ptok2019]. When tasks already require sustained attention, the benefits tend to diminish—for example, when participants are stabilized with a chin rest [@ptok2020], warned of an upcoming memory test [@geller2021], or required to spell rather than read words [@westerman1997].**

**Taken together, the stage-specific account would predict that blurring interacts with lexical difficulty to shape both response-time distributions and memory outcomes. Specifically, if blurring and word frequency jointly increase late-stage demands (indexed by** $\beta$**), downstream memory benefits should emerge only when sufficient cognitive resources remain—most likely for high-frequency words under otherwise fluent conditions. Experiment 2 tests these predictions by examining whether blur and frequency interact to influence early and late processing (ex-Gaussian parameters) and whether these effects translate into differences in subsequent memory.**

## Method

### Transparency and Openness

This study was preregistered https://osf.io/kjq3t. All raw and summary data, materials, and R scripts for pre-processing, analysis, and plotting for Experiment 2 can be found at our OSF page: https://osf.io/6sy7k/.

### Participants

**Participants were recruited via Prolific and compensated \$12 per hour. Using Prolific’s built-in filters, we restricted eligibility to monolingual, native English–speaking Americans residing in the United States, with normal or corrected-to-normal vision. A total of 465 participants completed the study. Three were excluded for completing the experiment more than once, and 13 were excluded for accuracy below .80; no participants were excluded for being under 18 years of age. This left 444 participants. Consistent with Experiments 1A and 1B, we randomly sampled participants to reach our preregistered sample size of 432 and to have an equal number of participants per list.  To be conservative and ensure adequate sensitivity to detect an attenuated interaction, we doubled the sample size of Experiments 1A and 1B and preregistered a target of 432 participants. As noted by @brysbaert2019, approximately 210 participants are required to detect a fully attenuated interaction with 80% power.**

**The study protocol was reviewed and approved by the Princeton University Institutional Review Board.**

### Materials

One hundred and eighty words (half low-frequency and half high-frequency) were adapted from @fernández-lópez2022. We further selected an additional 45 animal words from their stimuli. To make the experiment more feasible for online participants and to balance our conditions, we split the remaining non-animal words and presented 90 (half high-frequency, half low-frequency) non-animal words along with the 45 animal words during the study phase. This split maintained the 2:1 ratio of non-animal to animal words used in previous experiments [e.g., @fernández-lópez2022; @perea2018].

At test, an additional 90 non-animal words not shown during the study phase served as “new” items in the recognition task. We created six counterbalanced lists to ensure that each word appeared as both “old” and “new,” and under each of the three blurring conditions (clear, high-blur , low-blur ) across participants. Similar to nonwords in Experiments 1A and 1B, animal words were excluded from the final analysis. The animal word stimuli used by @fernández-lópez2022 varied in length (*M* = 5.3 letters; range: 3–9), but their average length closely matched that of the non-animal words (high-frequency: *M* = 5.3, range: 3–8; low-frequency: *M* = 5.3, range: 3–9). Animal words also covered a wide range of frequencies in the SUBTLEX database (*M* = 11.84 per million; range: 0.61–192.84).

### Procedure

We used the same procedure as Experiments 1B. The main difference is that instead of making a word/non-word decision, participants made a semantic categorization judgement (i.e., "is an animal" or "is not an animal"). You can view the task here: https://run.pavlovia.org/Jgeller112/hf_lf_sem_1.

## Results

### Accuracy

```{r}
rts_wf <- read_csv("https://osf.io/29hnd/download")
#rts_wf <- read_csv("data/SC_rt_cleaned.csv")
```

```{r}
rts_dim <- rts_wf |>
  filter(category == "NONAN")

blur_acc_wf <- rts_wf |>
  group_by(participant) |>
  dplyr::filter(rt >= .2 & rt <= 2.5) |>
  dplyr::filter(category == "NONAN")
```

The analysis of accuracy is based on `r dim(blur_acc_wf)[1]` data points, after removing fast (\> 2.5 s) and slow ( \< .2 s) RTs (`r round(1-dim(blur_acc_wf)[1]/dim(rts_dim)[1], 3)`).

```{r}
# Create custom contrast matrix manually
contrast_matrix <- matrix(
  c(
    -.5,
    -.5, # C
    .5,
    0, # HB
    -.5,
    .5
  ), # LB
  ncol = 2,
  byrow = TRUE
)

blur_acc_wf$blur <- as.factor(blur_acc_wf$blur)

# Assign to factor
contrasts(blur_acc_wf$blur) <- contrast_matrix

freqc <- hypr(HIGH ~ LOW, levels = c("HIGH", "LOW"))

blur_acc_wf$frequency <- as.factor(blur_acc_wf$frequency)

contrasts(blur_acc_wf$frequency) <- contr.hypothesis(freqc)
```

```{r}
#| eval: false
#|
prior_expsc <- c(set_prior("cauchy(0,.35)", class = "b"))

fit_acc_wf <- brm(
  corr ~
    blur *
      frequency +
      (1 + blur * frequency | participant) +
      (1 + blur | target),
  data = blur_acc_wf,
  warmup = 1000,
  iter = 5000,
  chains = 4,
  init = 0,
  family = bernoulli(),
  cores = 4,

  prior = prior_expsc,
  seed = 666,
  sample_prior = T,
  save_pars = save_pars(all = T),
  control = list(adapt_delta = 0.9),
  file = "acc_blmm_sc",
  backend = "cmdstanr",
  threads = threading(4)
)
```

```{r}
# get file from osf
fit_acc_sc <- read_rds("https://osf.io/2yb7g/download")
#fit_acc_sc <- read_rds("data/acc_blmm_sc_hblbc_moreints.rds")
```

```{r}
# get mean accuracy per condition
emm_acc <- emmeans(fit_acc_sc, ~ frequency + blur, type = "response") |>
  parameters::parameters(centrality = "mean")
```

```{r}
#| label: tbl-acc2
#| tbl-cap: "Posterior distribution estimates for accuracy (Experiment 2)"
#| apa-note: "CrI: 90% for one-sided tests and 95% for two-sided tests against 0. Posterior probability indicates the proportion of the posterior distribution that falls on one side of zero (either positive or negative), representing the probability that the effect is greater than or less than zero"

# Run hypothesis tests
a <- hypothesis(fit_acc_sc, "blur1 < 0") # high-blur  < (low-blur   + clear)/2
b <- hypothesis(fit_acc_sc, "blur2 = 0") # low-blur   = clear
c <- hypothesis(fit_acc_sc, "frequency1 = 0") # No frequency effect
d <- hypothesis(fit_acc_sc, "blur1:frequency1 = 0") # No interaction: HB vs. (LB + C)/2 × Freq
e <- hypothesis(fit_acc_sc, "blur2:frequency1 = 0") # No interaction: LB vs. C × Freq

# Helper to round hypothesis results
round_hypothesis <- function(hyp) {
  hyp$hypothesis <- hyp$hypothesis |>
    mutate(across(where(is.numeric), round, 3))
  hyp
}

# Apply rounding
a <- round_hypothesis(a)
b <- round_hypothesis(b)
c <- round_hypothesis(c)
d <- round_hypothesis(d)
e <- round_hypothesis(e)

# Combine and format table
tab <- bind_rows(
  a$hypothesis,
  b$hypothesis,
  c$hypothesis,
  d$hypothesis,
  e$hypothesis
) |>
  mutate(
    Hypothesis = c(
      "High blur < (Low blur + Clear)",
      "Low blur = Clear",
      "High Freq = Low Freq",
      "Blur × Frequency (High vs. Low/Clear) = 0",
      "Blur × Frequency (Low vs. Clear) = 0"
    ),
    `CrI*` = str_glue("[{CI.Lower}, {CI.Upper}]")
  ) |>
  rename(
    Mean = Estimate,
    SE = Est.Error,
    ER = Evid.Ratio,
    `Posterior Prob` = Post.Prob
  ) |>
  select(Hypothesis, Mean, SE, `CrI*`, ER, `Posterior Prob`)

# Create flextable
acc_exp2 <- flextable(tab) |>
  theme_apa() |>
  width(j = 1, width = 2.5) |> # widen the Hypothesis column
  set_table_properties(layout = "autofit")

acc_exp2
```

The full model summary for accuracy is presented in @tbl-acc2. We found strong evidence that high-blur red words were associated with lower accuracy compared to low-blur red and clear words, $b$ = `r a$hypothesis$Estimate`, 90% CrI \[`r a$hypothesis$CI.Lower`, `r a$hypothesis$CI.Upper`\], ER = `r process_ER_column(a$hypothesis$Evid.Ratio)`. The evidence for an accuracy difference between low-blur red and clear words was weak, $b$ = `r b$hypothesis$Estimate`, 90% CrI \[`r b$hypothesis$CI.Lower`, `r b$hypothesis$CI.Upper`\], ER = `r process_ER_column(b$hypothesis$Evid.Ratio)`. The credible interval spanned zero, and the evidence ratio suggested only weak support for either hypothesis. The evidence for a frequency effect was similarly weak , $b$ = `r c$hypothesis$Estimate`, 95% CrI \[`r c$hypothesis$CI.Lower`, `r c$hypothesis$CI.Upper`\], ER = `r c$hypothesis$Evid.Ratio`. Finally, interaction terms between blurring and word frequency yielded posterior distributions centered near zero, with 95% CrIs that included zero. Evidence ratios for these terms were close to 1, indicating substantial uncertainty and no clear preference for either the null or alternative hypothesis.

### RTs: Ex-Gaussian

Given the complexity of the model, we employed stronger priors to facilitate convergence. For the $\mu$ parameter, we specified the same prior used in Experiments 1A and 1B. For the $\beta$ parameter, we applied a more constrained prior: ${Normal}(0, 0.25)$. Default priors were retained for all remaining model parameters.

```{r}

p_rt_filter <- rts_wf |>
  filter(corr == 1, category == "NONAN")

p_rt_out <- p_rt_filter |>
  filter(rt >= .2 & rt <= 2.5) |>
  ungroup()

p_rt <- p_rt_filter |>
  filter(rt >= .2 & rt <= 2.5) |>
  group_by(frequency, blur) |>
  dplyr::summarise(rt = mean(rt)) |>
  dplyr::mutate(rt_ms = rt * 1000) |>
  select(-rt)

```

The analysis of RTs (correct trials and non-animal responses) is based on `r dim(p_rt_out)[1]` data points, after removing fast (\< .2 s) and slow (\> 2.5 s) RTs (1%).

```{r}
## Contrasts
#hypothesis
contrast_matrix <- matrix(
  c(
    -0.5,
    -0.5, # C
    0.5,
    0, # HB
    -0.5,
    0.5
  ), # LB
  ncol = 2,
  byrow = TRUE
)

# Apply to factor
p_rt_out$blur <- factor(p_rt_out$blur, levels = c("C", "HB", "LB"))
contrasts(p_rt_out$blur) <- contrast_matrix

freqc <- hypr(HIGH ~ LOW, levels = c("HIGH", "LOW"))
p_rt_out$frequency <- as.factor(p_rt_out$frequency)
contrasts(p_rt_out$frequency) <- contr.hypothesis(freqc)
```

```{r}
#| eval: false
# Model formula
bform_ex2 <- bf(
  rt ~
    blur *
      frequency +
      (1 + blur * frequency | p | participant) +
      (1 + blur | i | target),
  sigma ~
    blur *
      frequency +
      (1 + blur * frequency | p | participant) +
      (1 + blur | i | target),
  beta ~
    blur *
      frequency +
      (1 + blur * frequency | p | participant) +
      (1 + blur | i | target)
)
```

```{r}
#| eval: false
#|

prior <- c(
  prior(normal(0, 10), class = "b"),
  prior(normal(0, 1), dpar = "sigma"),
  prior(normal(0, 0.25), class = "b", dpar = "beta")
)

fit_exg1 <- brm(
  bform_exg1,
  data = p_rt_out,
  warmup = 1000,
  iter = 5000,
  chains = 4,
  family = exgaussian(),
  init = 0,
  prior = prior,
  cores = 4,
  control = list(adapt_delta = 0.8),
  sample_prior = T,
  seed = 666,
  save_pars = save_pars(all = T),
  backend = "cmdstanr",
  threads = threading(2)
)
```

```{r}
#| eval: false
#|
#highblurvs clear highblur vslowblur
#long time to load
fit_sc <- read_rds("http://osf.io/uwcjf/download")
#fit_sc <- read_rds("data/mod_exgauss_HBLBC.rds")
```

```{r}
#| label: tbl-expt2summary
#| tbl-cap: "Posterior distribution estimates for ex-Gaussian distribution (Experiment 2)."
#| apa-note: "CrI: 90% for one-sided tests and 95% for two-sided tests against 0. Posterior probability indicates the proportion of the posterior distribution that falls on one side of zero (either positive or negative), representing the probability that the effect is greater than or less than zero. Sigma and Beta parameters are on the log scale."

# Read CSVs from the folder and assign to objects
a <- read_csv("expt2_hypothesis/hypothesis_mu_blur1.csv")
b <- read_csv("expt2_hypothesis/hypothesis_mu_blur2.csv")
c <- read_csv("expt2_hypothesis/hypothesis_mu_frequency1.csv")
d <- read_csv("expt2_hypothesis/hypothesis_mu_blur1_frequency1.csv")
e <- read_csv("expt2_hypothesis/hypothesis_mu_blur2_frequency1.csv")

f <- read_csv("expt2_hypothesis/hypothesis_sigma_blur1.csv")
g <- read_csv("expt2_hypothesis/hypothesis_sigma_blur2.csv")
h <- read_csv("expt2_hypothesis/hypothesis_sigma_frequency1.csv")
i <- read_csv("expt2_hypothesis/hypothesis_sigma_blur1_frequency1.csv")
j <- read_csv("expt2_hypothesis/hypothesis_sigma_blur2_frequency1.csv")

k <- read_csv("expt2_hypothesis/hypothesis_beta_blur1.csv")
l <- read_csv("expt2_hypothesis/hypothesis_beta_blur2.csv")
m <- read_csv("expt2_hypothesis/hypothesis_beta_frequency1.csv")
n <- read_csv("expt2_hypothesis/hypothesis_beta_blur1_frequency1.csv")
o <- read_csv("expt2_hypothesis/hypothesis_beta_blur2_frequency1.csv")

# Combine and label all results
tab <- bind_rows(a, b, c, d, e, f, g, h, i, j, k, l, m, n, o) |>
  mutate(
    ER = as.numeric(Evid.Ratio),
    `CrI*` = str_glue("[{CI.Lower}, {CI.Upper}]"),
    Hypothesis = c(
      "High blur  > (vs. Clear/Low blur) ",
      "Low blur >  Clear",
      "High Frequency <  Low Frequency ",
      "High blur (vs. Low blur/Clear) × Frequency",
      "Low blur (vs. Clear) × Frequency",

      "High blur  > (vs. Clear/Low blur)",
      "Low blur <  Clear",
      "High Frequency < Low Frequency",
      "High blur (vs. Low blur/Clear) x Frequency",
      "Low blur (vs. Clear) × Frequency",

      "High blur >  (vs. Clear/Low blur)",
      "Low blur >  (vs. Clear)",
      "High Frequency < Low Frequency",
      "High blur (vs. Low blur/Clear) × Frequency",
      "Low blur (vs. Clear) × Frequency "
    )
  ) |>
  select(
    Hypothesis,
    Parameter,
    Estimate,
    Est.Error,
    `CrI*`,
    ER,
    Post.Prob
  ) |>
  rename(
    "Mean" = "Estimate",
    "SE" = "Est.Error",
    "Posterior Prob" = "Post.Prob"
  ) |>
  flextable() |>
  theme_apa() |>
  width(j = 1, width = 2.5) |> # widen the Hypothesis column
  set_table_properties(layout = "autofit")

tab
```

@tbl-expt2summary **provides a model summary. @fig-quantiledeltaexp2 visualizes RTs as quantile and delta plots, highlighting how blurring and word frequency shaped processing during word recognition. High-blurred words showed larger central tendency shifts (**$\mu$**) compared to the average of clear and low-blurred words, *b* = `r a$Estimate`, 90% CrI \[`r a$CI.Lower`, `r a$CI.Upper`\], ER = `r process_ER_column(a$Evid.Ratio)`. Low-blurred words also produced greater shifts relative to clear words, *b* = `r b$Estimate`, 90% CrI \[`r b$CI.Lower`, `r b$CI.Upper`\], ER = `r process_ER_column(b$Evid.Ratio)`.**

**There was a consistent word frequency effect: high-frequency words produced smaller shifts than low-frequency words, *b* = `r c$Estimate`, 90% CrI \[`r c$CI.Lower`, `r c$CI.Upper`\], ER = `r process_ER_column(c$Evid.Ratio)`. Blur × Frequency interactions on** $\mu$ **were centered near zero, providing little evidence for an interaction. Specifically, the high-blur (vs. clear/low-blur ) × Frequency interaction was *b* = `r d$Estimate`, 90% CrI \[`r d$CI.Lower`, `r d$CI.Upper`\], ER = `r d$Evid.Ratio`, and the low-blur (vs. clear) × Frequency interaction was *b* = `r e$Estimate`, 90% CrI \[`r e$CI.Lower`, `r e$CI.Upper`\], ER = `r e$Evid.Ratio`.**

**For variability (**$\sigma$**), responses to high-blurred words were more variable than those to clear and low-blurred words, *b* = `r f$Estimate`, 90% CrI \[`r f$CI.Lower`, `r f$CI.Upper`\], ER = `r process_ER_column(f$Evid.Ratio)`. The difference between low-blurred and clear words was weak, *b* = `r g$Estimate`, 90% CrI \[`r g$CI.Lower`, `r g$CI.Upper`\], ER = `r g$Evid.Ratio`. Frequency also modulated variability, with high-frequency words showing less variability than low-frequency words, *b* = `r h$Estimate`, 90% CrI \[`r h$CI.Lower`, `r h$CI.Upper`\], ER = `r h$Evid.Ratio`. Blur × Frequency interactions on** $\sigma$ **provided mixed evidence: the high-blur (vs. clear/low-blur ) × Frequency interaction was *b* = `r i$Estimate`, 90% CrI \[`r i$CI.Lower`, `r i$CI.Upper`\], ER = `r i$Evid.Ratio`, whereas the low-blur (vs. clear) × Frequency interaction was *b* = `r j$Estimate`, 90% CrI \[`r j$CI.Lower`, `r j$CI.Upper`\], ER = `r j$Evid.Ratio`.**

**Posterior estimates indicated greater skew (**$\beta$**) for high-blurred words compared to clear and low-blurred words, *b* = `r k$Estimate`, 90% CrI \[`r k$CI.Lower`, `r k$CI.Upper`\], ER = `r process_ER_column(k$Evid.Ratio)`. The difference between low-blurred and clear words was negligible, *b* = `r l$Estimate`, 90% CrI \[`r l$CI.Lower`, `r l$CI.Upper`\], ER = `r l$Evid.Ratio`. Frequency robustly affected skew: high-frequency words showed less skew than low-frequency words, *b* = `r m$Estimate`, 90% CrI \[`r m$CI.Lower`, `r m$CI.Upper`\], ER = `r m$Evid.Ratio`. Evidence for interactions on skew was more nuanced. The high-blur (vs. clear/low-blur ) × Frequency interaction was supported, *b* = `r n$Estimate`, 90% CrI \[`r n$CI.Lower`, `r n$CI.Upper`\], ER = `r n$Evid.Ratio`. The low-blur (vs. clear) × Frequency interaction suggested greater skewing for high-frequency words than for low-frequency words, although the CrI included 0, *b* = `r o$Estimate`, 90% CrI \[`r o$CI.Lower`, `r o$CI.Upper`\], ER = `r o$Evid.Ratio`.**

```{r}
#Delta plots (one per subject)
quibble <- function(x, q = seq(.1, .9, .2)) {
  tibble(x = quantile(x, q), q = q)
}

data.quantiles <- p_rt_out |>
  dplyr::group_by(participant, blur, frequency, corr) |>
  dplyr::mutate(rt_ms = rt * 1000) |>
  dplyr::summarise(RT = list(quibble(rt_ms, seq(.1, .9, .2)))) |>
  tidyr::unnest(RT) |>
  ungroup()

data.delta <- data.quantiles |>
  dplyr::group_by(participant, blur, frequency, q) |>
  dplyr::summarize(RT = mean(x)) |>
  ungroup()
```

```{r}
#Delta plots (based on vincentiles)
vincentiles <- data.quantiles |>
  dplyr::group_by(blur, frequency, q) |>
  dplyr::summarize(RT = mean(x)) |>
  ungroup()

v = vincentiles |>
  dplyr::group_by(blur, frequency, q) |>
  dplyr::summarise(MRT = mean(RT)) |>
  ungroup()

v$blur <- factor(v$blur, level = c("HB", "LB", "C"))

p <- ggplot(v, aes(x = q, y = MRT, colour = blur)) +
  facet_grid(
    ~frequency,
    labeller = labeller(
      frequency = c(
        "HIGH" = "High Frequency",
        "LOW" = "Low Frequency"
      )
    )
  ) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  scale_y_continuous(breaks = seq(500, 1600, 100)) +
  coord_cartesian(ylim = c(500, 1600)) +
  scale_x_continuous(breaks = seq(.1, .9, .2)) +
  geom_label_repel(
    data = v,
    aes(x = q, y = MRT, label = round(MRT, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5, 
     size=10
  ) +
  labs(x = "Quantiles", y = "Response latencies in ms", tag = "A") + 
 theme_minimal(base_size = 16) +
  theme(legend.position = "bottom") +
ggokabeito::scale_colour_okabe_ito(
    name = "Blur Condition",
    labels = c("C" = "Clear", "HB" = "High blur", "LB" = "Low blur")
  ) 
```

```{r}
p2 <- ggplot(data = v, aes(y = MRT, x = frequency, color = q)) +
  facet_grid(~blur) +
  geom_line() +
  geom_point(size = 4)
```

```{r}
v_chb <- v |>
  dplyr::filter(blur == "C" | blur == "HB") |>
  dplyr::group_by(frequency, q) |>
  mutate(mean_rt = mean(MRT)) |>
  ungroup() |>
  tidyr::pivot_wider(names_from = "blur", values_from = "MRT") |>
  mutate(diff = HB - C)

v_chb_freq <- v |>
  dplyr::group_by(blur, q) |>
  mutate(mean_rt = mean(MRT)) |>
  ungroup() |>
  tidyr::pivot_wider(names_from = "frequency", values_from = "MRT") |>
  mutate(diff = LOW - HIGH)

base_theme <- theme_minimal(base_size = 16) +
  theme(
    legend.position = "none",
    panel.border = element_blank(),
    strip.background = element_blank()
  )

p1 <- ggplot(v_chb, aes(x = mean_rt, y = diff)) +
  facet_grid(
    ~frequency,
    labeller = labeller(
      frequency = c("HIGH" = "High Frequency", "LOW" = "Low Frequency")
    )
  ) +
  geom_abline(intercept = 0, slope = 0) +
  geom_line(size = 1, colour = "black") +
  geom_point(size = 3, colour = "black") +
  scale_y_continuous(breaks = seq(10, 500, 50)) +
  scale_x_continuous(breaks = seq(600, 1100, 100)) +
  coord_cartesian(xlim = c(600, 1100), ylim = c(10, 500)) +
  geom_label_repel(
    data = v_chb,
    aes(y = diff, label = round(diff, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5, 
      size=10
  ) +
  labs(
    title = "High blur vs. Clear",
    x = "",
    y = "Group Differences",
    tag = "B"
  ) +
  base_theme


```

```{r}
v_clb <- v |>
  dplyr::group_by(frequency, q) |>
  mutate(mean_rt = mean(MRT)) |>
  ungroup() |>
  tidyr::pivot_wider(names_from = "blur", values_from = "MRT") |>
  mutate(diff = LB - C)

p2 <- ggplot(v_clb, aes(x = mean_rt, y = diff)) +
  facet_grid(
    ~frequency,
    labeller = labeller(
      frequency = c(
        "HIGH" = "High Frequency",
        "LOW" = "Low Frequency"
      )
    )
  ) +
  geom_abline(intercept = 0, slope = 0) +
  geom_line(size = 1, colour = "black") +
  geom_point(size = 3, colour = "black") +
  theme_minimal(base_size = 16) +
  theme(legend.position = "none") +
  scale_y_continuous(breaks = seq(10, 500, 50)) +
  scale_x_continuous(breaks = seq(600, 1100, 100)) +
  coord_cartesian(xlim = c(600, 1100), ylim = c(10, 500)) +
  geom_label_repel(
    data = v_clb,
    aes(y = diff, label = round(diff, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5, 
      size=10
  ) +
  labs(
    title = "Clear vs. Low blur",
    x = "Mean RT per quantile",
    y = ""
  )
```

```{r}
v_hlb <- v |>
  dplyr::filter(blur == "HB" | blur == "LB") |>
  dplyr::group_by(frequency, q) |>
  mutate(mean_rt = mean(MRT)) |>
  ungroup() |>
  tidyr::pivot_wider(names_from = "blur", values_from = "MRT") |>
  mutate(diff = HB - LB)

p3 <- ggplot(v_hlb, aes(x = mean_rt, y = diff)) +
  facet_grid(
    ~frequency,
    labeller = labeller(
      frequency = c(
        "HIGH" = "High Frequency",
        "LOW" = "Low Frequency"
      )
    )
  ) +
  geom_abline(intercept = 0, slope = 0) +
  geom_line(size = 1, colour = "black") +
  geom_point(size = 3, colour = "black") +
  theme_minimal(base_size = 16) +
  theme(legend.position = "none") +
  scale_y_continuous(breaks = seq(10, 500, 50)) +
  coord_cartesian(ylim = c(10, 500)) +
  scale_x_continuous(breaks = seq(600, 1100, 100)) +
  coord_cartesian(xlim = c(600, 1100), ylim = c(10, 500)) +
  geom_label_repel(
    data = v_hlb,
    aes(y = diff, label = round(diff, 0)),
    color = "black",
    min.segment.length = 0,
    seed = 42,
    box.padding = 0.5, 
      size=10
  ) +
  labs(title = "High blur vs. Low blur", x = "", y = "")
```

```{r}
#| label: fig-quantiledeltaexp2
#| fig-cap: "Group RT distributions in the blurring and word frequency manipulations in word stimuli. A. Quantile plots with each point represents the average RT quantiles (.1, .3, .5, .7,and .9) in each condition. B. Delta plots obtained by computing the quantiles for each participant and subsequently averaging the obtained values for each quantile over the participants and subtracting the values from each condition."
#| fig-width: 24
#| fig-height: 10

# Create bottom row with p1, p2, p3
bottom_row <- plot_grid(p1, p2, p3, ncol = 3)

# Stack p on top of the bottom_row
final_plot <- plot_grid(p, bottom_row, ncol = 1)

final_plot

```

```{r}
#| label: tbl-freq
#| tbl-cap: "Mean response time (in ms) for the word frequency effects across the .1, .3, .5, .7, and .9 quantiles of the RT distribution as a function of blurring. These values correspond to the quantile effects for Experiment 2."
#diff
v_wf <- v |>
  dplyr::group_by(blur, q) |>
  tidyr::pivot_wider(names_from = "frequency", values_from = "MRT") |>
  mutate(Diff = LOW - HIGH) |>
  rename("Blur" = "blur") |>
  mutate(
    Blur = ifelse(
      Blur == "C",
      "Clear",
      ifelse(Blur == "HB", "High blur", "Low blur")
    )
  ) |>
  ungroup()

v_wf |>
  select(Blur, q, Diff) |>
  pivot_wider(names_from = "q", values_from = "Diff") |>
  mutate(across(where(is.numeric), ~ round(.x, 3))) |>
  flextable() |>
  theme_apa() |>
  width(j = 1, width = 2.5) |> # widen the Hypothesis column
  set_table_properties(layout = "autofit")
```

### Recognition Memory

To aid in model convergence, we used a binomial (probit) family rather than a Bernoulli family when modeling our results. While both approaches are appropriate for binary outcomes, the binomial model allowed us to aggregate responses within each condition, reducing the number of observations and easing computational demands. This aggregation improved sampling efficiency and stability, particularly given the complexity of the full factorial structure. However, as a trade-off, we were unable to model random intercepts and slopes for individual items, since aggregation collapses trial-level variability.

```{r}
# mem_sc <- read_csv("https://osf.io/eapu5/download")
mem_sc <- read_csv("https://osf.io/eapu5/download")
```

```{r}
dat_binom <- mem_sc %>%
  count(participant, isold, blur, frequency, sayold) %>%
  tidyr::pivot_wider(
    names_from = sayold,
    values_from = n,
    values_fill = 0,
    names_prefix = "sayold_"
  ) %>%
  rename(
    success = sayold_1,
    failure = sayold_0
  ) %>%
  mutate(total = success + failure)

```

```{r}
## Contrasts
#hypothesis
contrast_matrix <- matrix(
  c(
    -0.5,
    -0.5, # C
    0.5,
    0, # HB
    -0.5,
    0.5
  ), # LB
  ncol = 2,
  byrow = TRUE
)

# Apply to factor
dat_binom$blur <- factor(dat_binom$blur, levels = c("C", "HB", "LB"))
contrasts(dat_binom$blur) <- contrast_matrix

HF_cont <- hypr(HIGH ~ LOW, levels = c("HIGH", "LOW"))

dat_binom$frequency <- as.factor(dat_binom$frequency)

contrasts(dat_binom$frequency) <- contr.hypothesis(HF_cont)
```

```{r}
#| eval: false
#|
prior_exp <- c(set_prior("cauchy(0,.35)", class = "b"))

fit_sc_sdt <- brm(
  formula = success | trials(total) ~
    isold * blur * frequency + (1 + isold * blur * frequency | participant),
  data = dat_binom,
  family = binomial(link = "probit"),
  prior = prior_exp,
  chains = 4,
  cores = 4,
  iter = 5000,
  sample_prior = TRUE,
  backend = "cmdstanr",
  threads = threading(2),
  file = "blmm_sdt_sc_hblbc",
  control = list(adapt_delta = 0.95)
)
```

```{r}
# read in file from osf
# fit_sc_mem <- read_rds("https://osf.io/kh43z/download")
fit_sc_mem <- read_rds("https://osf.io/kh43z/download")
```

```{r}
emm_m2_d1 <- emmeans(fit_sc_mem, ~ isold | blur * frequency) |>
  contrast("revpairwise")

emm_m2_d2 <- emmeans(fit_sc_mem, ~ isold + blur * frequency) |>
  contrast(interaction = c("revpairwise", "pairwise"), by = "frequency")

# (Negative) criteria
emm_m2_c1 <- emmeans(fit_sc_mem, ~ blur * frequency)
emm_m2_c2 <- emmeans(fit_sc_mem, ~ blur | frequency) |>
  contrast("pairwise")
```

```{r}
#| label: fig-m2-emmeans
#| fig-cap: Estimated posterior distributions for d-prime and criterion, and differences between all conditions with 95% CrIs
#| fig-width: 12
#| fig-height: 10

blur_level <- c(
  "Clear",
  "High blur",
  "Low blur",
  "Clear-High blur",
  "Clear-Low blur",
  "High blur-Low blur"
)

tmp <- bind_rows(
  bind_rows(
    gather_emmeans_draws(emm_m2_d1) |>
      group_by(blur, frequency) |>
      select(-contrast),
    gather_emmeans_draws(emm_m2_d2) |>
      rename(
        blur = blur_pairwise
      ) |>
      group_by(blur, frequency) |>
      select(-isold_revpairwise)
  ),
  bind_rows(
    gather_emmeans_draws(emm_m2_c1),
    gather_emmeans_draws(emm_m2_c2) |>
      rename(
        blur = contrast
      )
  ),
  .id = "Parameter"
) |>
  ungroup() |>
  mutate(Parameter = factor(Parameter, labels = c("d-prime", "Criterion"))) |>
  mutate(
    t = if_else(str_detect(blur, " - "), "Differences", "Group means") |>
      fct_inorder(),
    blur = fct_inorder(blur),
    frequency = ifelse(frequency == "HIGH", "High", "Low")
  )
# Convert blur to an ordered factor to control spacing
# Convert blur to a factor with predefined order
tmp |>
  mutate(
    .value = if_else(Parameter == "Criterion", .value * -1, .value),
    Parameter = fct_rev(Parameter)
  ) |>
  ggplot(aes(x = as.numeric(blur), y = .value, fill = frequency)) +
  labs(
    x = "Blurring Level (or difference)",
    y = "Parameter value",
    fill = "Frequency"
  ) +
  geom_hline(yintercept = 0, linewidth = .25) +

  # Replace scale_x_discrete with scale_x_continuous
  scale_x_continuous(
    breaks = 1:6, # Assuming you have 6 unique blur levels
    labels = blur_level # Your predefined labels
  ) +

  scale_slab_alpha_discrete(range = c(1, .5)) +

  stat_halfeye(
    normalize = "xy",
    width = 0.44,
    slab_color = "black",
    point_interval = "mean_qi",
    .width = c(.95),
    aes(
      side = ifelse(frequency == "High", "left", "right"),
      x = ifelse(
        frequency == "High",
        as.numeric(blur) - .08,
        as.numeric(blur) + .08
      )
    )
  ) +

  guides(slab_alpha = "none") +
  facet_grid(Parameter ~ t, scales = "free") +
  ggokabeito::scale_fill_okabe_ito() +
  theme_minimal(base_size = 16) +
  theme(
    strip.background = element_rect(fill = "black", color = "black"),
    strip.text = element_text(color = "white", face = "bold")
  )

ggsave("figures/dprime_expt2.png", width = 14, height = 8, dpi = 500)
```

```{r}
#| echo: false
# Run hypotheses
a <- hypothesis(fit_sc_mem, "isold:blur1 > 0")
b <- hypothesis(fit_sc_mem, "isold:blur2 = 0")
c <- hypothesis(fit_sc_mem, "isold:frequency1 > 0")
d <- hypothesis(fit_sc_mem, "isold:blur1:frequency1 > 0")
e <- hypothesis(fit_sc_mem, "isold:blur2:frequency1 > 0")

# Extract and round each hypothesis table
a$hypothesis <- a$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
b$hypothesis <- b$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
c$hypothesis <- c$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
d$hypothesis <- d$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))
e$hypothesis <- e$hypothesis |>
  mutate(across(where(is.numeric), ~ round(.x, 3)))

# Combine into one table
tab <- bind_rows(
  a$hypothesis,
  b$hypothesis,
  c$hypothesis,
  d$hypothesis,
  e$hypothesis
) |>
  mutate(Evid.Ratio = as.numeric(Evid.Ratio)) |>
  select(-Star)

# Optionally ensure everything except the first column is rounded again (belt-and-suspenders)
tab[, -1] <- t(apply(tab[, -1], 1, round, digits = 3))
```

#### Sensitivity

Consistent with Experiments 1A and 1B, sensitivity in recognition memory was higher for high-blur red words compared to both clear and low-blur red words (see @fig-m2-emmeans), $\beta$ = `r a$hypothesis$Estimate`, 90% CrI \[`r a$hypothesis$CI.Lower`, `r a$hypothesis$CI.Upper`\], ER = `r a$hypothesis$Evid.Ratio`. The difference in recognition between clear and low-blur red words was negligible, with strong evidence in favor of the null hypothesis: $\beta$ = `r b$hypothesis$Estimate`, 95% CrI \[`r b$hypothesis$CI.Lower`, `r b$hypothesis$CI.Upper`\], ER = `r b$hypothesis$Evid.Ratio`.

Sensitivity was higher for low-frequency words compared to high-frequency words, $\beta$ = `r c$hypothesis$Estimate`, 90% CrI \[`r c$hypothesis$CI.Lower`, `r c$hypothesis$CI.Upper`\], ER = `r c$hypothesis$Evid.Ratio`. Crucially, there was strong evidence for an interaction between blur and frequency, such that **high-frequency words, but not low-frequency words**, showed a selective memory benefit under high-blur ring: $\beta$ = `r d$hypothesis$Estimate`, 95% CrI \[`r d$hypothesis$CI.Lower`, `r d$hypothesis$CI.Upper`\], ER = `r d$hypothesis$Evid.Ratio`. A second interaction emerged for the comparison between low-blur and clear words: $\beta$ = `r e$hypothesis$Estimate`, 90% CrI \[`r e$hypothesis$CI.Lower`, `r e$hypothesis$CI.Upper`\], ER = `r e$hypothesis$Evid.Ratio`. In this case, recognition was also better for high-frequency words when stimuli were presented with low-blur .

## Discussion

**Experiment 2 examined how *later stages of processing* contribute to the memory boost sometimes produced by disfluent stimuli, and how this interacts with word frequency. We combined a word frequency manipulation with a semantic categorization task and looked at the full distribution of response times.**

**We found that the word frequency effect was especially strong for highly blurred words (compared to clear or lightly blurred words). This effect grew larger at the slower end of the response time distribution, producing a steeper slope across quantiles quantiles** (see @tbl-freq and @fig-quantiledeltaexp2) **. In terms of modeling, this was reflected in changes to the** $\beta$ **parameter of the ex-Gaussian distribution. Put simply, when words were blurred and varied in frequency, readers showed more very slow responses—consistent with greater demands on late-stage processing. Similar effects have been observed with other kinds of difficult-to-read text, such as handwritten cursive [@barnhart2010; @vergara-martínez2021].**

**Turning to memory, both high- and low-blurred words produced a perceptual disfluency effect relative to clear words. However, the benefit depended on frequency. High-frequency words showed a clear memory advantage under both blur conditions. Low-frequency words, in contrast, did not benefit. This asymmetry is informative: in the RT data, high-blur produced a significant interaction on the** $\beta$ **parameter, with low-frequency words showing a disproportionately long tail (slower responses) — a marker of greater late-stage processing difficulty. Yet this extra effort did not translate into better memory. By comparison, high-frequency words showed only modest increases in the tail but did reap a memory benefit.**

**Taken together, these findings suggest that greater late-stage processing (as reflected in longer response time tails) may be necessary but not sufficient for memory benefits from disfluency. In our study, high-blur exaggerated the word frequency effect on the tail of the distribution, indicating more prolonged or effortful processing. However, only under some conditions (e.g., high-frequency words) did this additional processing translate into improved memory performance.**

**Interestingly, low-blur also interacted with word frequency. High-frequency words showed a memory advantage under low-blur , even though the statistical model suggested only modest changes in the tail of the response time distribution. The evidence ratio indicated support for a positive effect, although the credible interval included zero. What matters for interpretation is the*direction*: unlike the high-blur condition, under low-blur it was the high-frequency words that showed more signs of late-stage processing than the low-frequency words.**

**Why might this be? For high-frequency words, low-blur may have disrupted the usually automatic recognition process just enough to slow people down and force some extra lexical or semantic processing. Rather than being harmful, this mild disruption could have deepened encoding, resulting in a memory benefit. By contrast, low-frequency words may not have been accessible enough to benefit from the same subtle increase in processing effort.**

**This pattern highlights that memory benefits from disfluency are not simply a matter of “more effort is better.” Instead, they appear when perceptual difficulty interacts with lexical accessibility in the right way. Modest disfluency can encourage extra elaboration of familiar words without overwhelming cognitive resources, leading to stronger memory. But when disfluency is too great, or when the items are already hard to process, the added effort may not yield any benefit.**

# General Discussion

Interfering with stimulus perception during encoding can sometimes improve later explicit memory. The mixed data on perceptual disfluency has called into question the utility of such manipulations in the learning domain. One of the main aims of the current set of experiments was to examine the underlying mechanisms of the perceptual disfluency effect to better understand when perceptual disfluency aids memory and when it does not. To this end, our study delved into the impact of one type of perceptual disfluency--blurring (i.e., low-blur ring and high-blur ring)--on the process of encoding, as assessed through a LDT (Experiments 1A and 1B), and a semantic categorization task (Experiment 2). RT distributions were analyzed with an ex-Gaussian model (Experiments 1A, 1B, 2) and DDM (Experiments 1A and 1B). Application of this model offered a comprehensive descriptive and theoretical framework through which to examine the perceptual disfluency effect.

To recapitulate our findings, during encoding, high-blur red words showed greater distributional shifting and skewing compared to clear and low-blur red words. Conversely, low-blur red words compared to clear words showed greater distributional shifting, but there was no difference in skewing. Turning to recognition memory, high-blur red words were more likely to be recognized at test compared to clear words and low-blur red words. This pattern arose regardless if context was reinstated at test (Experiment 1B). This pattern replicates the results from @rosner2015. In addition, we showed word frequency (Experiment 2) also modulates the disfluency effect. Namely, **high-blurred low-frequency words** did not show a disfluency effect.

These findings have several implications. At a theoretical level, the current data suggests that in order for perceptual disfluency to benefit memory it has to be disfluent enough to affect both early and late stages of processing. A manipulation that only produces a general slowing of responses is not sufficient to enact an mnemonic effect. However, an important caveat to this result is that processes during encoding of the word itself are not enough to produce an mnemonic benefit. In Experiment 2, we did not observe better memory for high-blurred low-frequency words which are the hardest and presumably receive the most top-down processing. We only observed a disfluency effect for high-frequency -high-blur red words. This points to the importance of control processes and processing limitations in producing the disfluency effect.

**We argue that the current findings align most closely with the stage-specific account proposed by @ptok2019. Although this account was originally developed to explain memory effects requiring conflict during encoding (e.g., semantic interference), it also provides a useful framework for understanding our results. Indeed, @ptok2019 and @ptok2020 suggested links between their framework, perceptual disfluency effects, and desirable difficulties more broadly. According to the stage-specific account, memory performance depends on the nature of processing during encoding and the deployment of cognitive control mechanisms.**

**In our experiments, participants judged whether letter strings were words or nonwords (Experiments 1A and 1B) or whether a word belonged to the animal category (Experiment 2). For skilled readers, such tasks are executed automatically and fluently. When paired with perceptual disfluency, this automaticity can lead to memory advantages for disfluent stimuli. However, when we manipulated word frequency, recognizing low-frequency words required greater effort and attentional resources on top of the perceptual disfluency introduced by blurring, further increasing task demands. These heightened processing requirements may have offset the potential benefits of blurring, as more resources were diverted to lexical access.**

**Evidence for this capacity-limited view comes from several sources. For example, @geller2018 showed that both easy-to-read and hard-to-read cursive words were remembered better than computer-print words, though the advantage was substantially larger for easier to read cursive words. Similarly, participants with lower working memory capacity benefit less from perceptual disfluency than those with higher capacity [@lehmann2015]. At a broader level, @wenzel2019 suggested that intelligence may moderate when desirable difficulties enhance learning.**

**Complementing this stage-specific perspective, @gagl2020 proposed a more stage-agnostic framework: the orthographic prediction error (OPE) model. Drawing on fMRI and EEG data, this model holds that reading involves generating visual–orthographic predictions and comparing them to incoming input. Visual degradation increases OPE—the mismatch between expected and observed letter input—and when predictions are impaired or suspended due to unpredictability, the benefits of top-down facilitation are reduced. Processing then relies more heavily on bottom-up input, which can slow responses and alter encoding quality. This framework helps clarify how perceptual disfluency influences both response-time distributions and memory outcomes, while situating the stage-specific account within a broader predictive-processing view. Future research may further elucidate how these perspectives converge.**

At a methodological level, our experiments demonstrate that a straightforward blurring manipulation can benefit memory, which we observed whether or not we reinstated the context during testing. However, blurring has to be sufficiently difficult to do so. If the secondary task requires too much attentional control the effect might not be observed or attenuated.

More significantly, our current experiments underscore the benefits of using mathematical and computational models to examine stages or levels of processing during encoding. A frequent critique of the ex-Gaussian model is that it lacks a clear correspondence to specific cognitive constructs [@fitousi2020]. To address this limitation, we also fit a drift diffusion model (DDM) to the encoding data from Experiments 1A and 1B (see Appendix A). Both models converged on similar findings: response time distributions were differentially affected by the degree of visual blur. Words with low-blur primarily influenced early or non-decision stages of processing whereas highly blurred words impacted both early and later stages. These findings suggest that both the ex-Gaussian and DDM are sensitive to perceptual disfluency and can help uncover underlying cognitive mechanisms during encoding [but see @hu2022 for a DDM account of perceptual disfluency at retreival]. Although the models converged on similar patterns, it remains an open question whether one should be favored over the other.

Furthermore, our distribution modeling of RTs appears to be a more sensitive method. Although we found weak evidence for differences between clean and low-blur red conditions in measures like accuracy, we did notice variations in non-decision time and a shift in the response time distribution for low-blur red words compared to clear words. We recommend that future studies employ distribution modeling and DDM to decompose response times and directly quantify the impact of perceptual disfluency on encoding.

Finally, at a practical level, our findings suggest that blurring can benefit later memory. However, several caveats should be noted. First, these experiments were conducted online using relatively simple materials (i.e., list learning). It remains unclear how well these effects would generalize to classroom settings or more educationally realistic materials [@geller2020; @geller2021]. **Second, all three experiments employed a mixed-list design. Although perceptual disfluency effects have been observed with both mixed and pure/blocked designs [@geller2018; @rosner2015], the mixed-list paradigm is not representative of typical classroom contexts.** Third, participants were not informed about the upcoming recognition test. Prior work has shown that low test expectancy can be an important moderator of disfluency effects [@geller2021]. Lastly, while we did not establish a region of practical equivalence (ROPE), the effect sizes observed here appear to be small. Using the default ROPE from the *bayestestR* package (−0.10 to 0.10 in standardized units) [@bayestestR], many of the critical contrasts fell entirely within or overlapped with this region, suggesting negligible differences. For applied contexts, these effects are likely well below the smallest effect size of interest.

This is not to say that all research on perceptual disfluency is unwarranted. As emphasized in @geller2021, a promising direction for future work is to examine how perceptual factors influence everyday processing and memory, particularly in situations where encoding is largely incidental [@castel2015]. In addition, educators and researchers might leverage computational modeling approaches to guide the selection of stimuli in more ecologically valid settings, testing whether perceptual disfluency effects can be reliably obtained under conditions that more closely approximate real-world learning environments.

These results also provide some context for the large number of replication failures. Many prior studies on disfluency do not carefully ensure that the manipulation is, in fact, experienced as disfluent. More often than not, such work relies on simple two-level manipulations (fluent vs. disfluent) and employs analytic approaches that may not be well suited to the structure of response time data. As we have attempted to demonstrate here, it is crucial to consider the entire RT distribution. By examining distributional shifts across different levels of disfluency, we obtained a richer understanding of the processing stages affected during encoding. We hope that researchers in learning and memory will increasingly adopt these tools, not only to clarify the mechanisms underlying perceptual disfluency effects, but also to investigate encoding in contexts characterized by substantial cognitive conflict.

## Conclusion

Our paper contributes nuanced insights to the intricate relationship between perceptual disfluency and memory encoding. We have shown that perceptual disfluency can aid in memory retention, but its efficacy is contingent upon the degree of disfluency and other contextual factors such as word frequency. Our findings endorse the stage-specific account, emphasizing the role of cognitive control mechanisms in the observed memory advantages with perceptual disfluency. Furthermore, our methodological contributions, employing an ex-Gaussian model and DDM, not only validate the benefits of examining RT distributions, but also open new avenues for future research in learning and memory studies. We caution, however, that the applicability of these findings in real-world educational settings remains an open question, and the effect sizes observed were relatively small, thus warranting further investigation. Ultimately, this work stands as a call to action for a more comprehensive, nuanced approach to studying perceptual disfluency, incorporating both advanced statistical methods and a more exhaustive range of experimental conditions to better elucidate when and how disfluency can facilitate memory.

# References

::: {#refs}
:::

# DDM Results

**The purpose of this appendix is to provide a brief description of how the diffusion model accounts for the data presented in the main article. Although fitting the diffusion model was included in our preregistration plan, we chose to present these analyses here rather than in the main text in order to enhance readability.**

We fit a hierarchical Bayesian Wiener diffusion model in `{brms}` [@vandekerckhove2011] with accuracy coding, estimating drift rate ($v$), boundary separation (response caution; fixed at 0.5), and non-decision time ($T\_{er}$).

### Experiment 1A

```{r}
blur_rt_diff <- rts |>
  group_by(participant) |>
  dplyr::filter(rt >= .2 & rt <= 2.5) |>
  dplyr::filter(lex == "m")
```

```{r}
#| eval: false

formula <- bf(
  rt | dec(corr) ~
    0 + blur + (1 + blur | p | participant) + (1 + blur | i | string),
  ndt ~ 0 + blur + (1 + blur | p | participant) + (1 + blur | i | string),
  bias = .5
)


bprior <- prior(normal(0, 1), class = b) +
  prior(normal(0, 1), class = b, dpar = ndt) +
  prior(normal(0, 1), class = sd) +
  prior(normal(0, 1), class = sd, dpar = ndt) +
  prior("normal(0, 0.3)", class = "sd", group = "participant") +
  prior("normal(0, 0.3)", class = "sd", group = "string")
```

```{r}
#| eval: false
#|
make_stancode(
  formula,
  family = wiener(
    link_bs = "identity",
    link_ndt = "identity",
    link_bias = "identity"
  ),
  data = blur_rt_diff,
  prior = bprior
)

tmp_dat <- make_standata(
  formula,
  family = wiener(
    link_bs = "identity",
    link_ndt = "identity",
    link_bias = "identity"
  ),
  data = blur_rt_diff,
  prior = bprior
)
str(tmp_dat, 1, give.attr = FALSE)

initfun <- function() {
  list(
    b = rnorm(tmp_dat$K),
    bs = .5,
    b_ndt = runif(tmp_dat$K_ndt, 0.1, 0.15),
    sd_1 = runif(tmp_dat$M_1, 0.5, 1),
    sd_2 = runif(tmp_dat$M_2, 0.5, 1),
    z_1 = matrix(
      rnorm(tmp_dat$M_1 * tmp_dat$N_1, 0, 0.01),
      tmp_dat$M_1,
      tmp_dat$N_1
    ),
    z_2 = matrix(
      rnorm(tmp_dat$M_2 * tmp_dat$N_2, 0, 0.01),
      tmp_dat$M_2,
      tmp_dat$N_2
    ),
    L_1 = diag(tmp_dat$M_1),
    L_2 = diag(tmp_dat$M_2)
  )
}
```

```{r}
#| eval: false

fit_wiener1 <- brm(
  formula,
  data = blur_rt_diff,
  family = wiener(
    link_bs = "identity",
    link_ndt = "identity",
    link_bias = "identity"
  ),
  prior = bprior,
  init = initfun,
  iter = 2000,
  warmup = 500,
  chains = 4,
  cores = 4,
  file = "weiner_diff_1",
  backend = "cmdstanr",
  threads = threading(4),
  control = list(max_treedepth = 15)
)
```

```{r}
#diff object on osf
fit_wiener <- read_rds("https://osf.io/hqauz/download")
#fit_wiener <- read_rds("data/weiner_diff_1.rds")
```

```{r}
#| label: tbl-diffexpt1A
#| tbl-cap: "Posterior distribution estimates for DDM (Experiment 1A)"
#| apa-note: "CrI: 90% for one-sided tests and 95% for two-sided tests against 0. Posterior probability indicates the proportion of the posterior distribution that falls on one side of zero (either positive or negative), representing the probability that the effect is greater than or less than zero"

# Define contrasts using averages and differences
a <- hypothesis(fit_wiener, "blurHB - ((blurLB + blurC / 2)) < 0")
b <- hypothesis(fit_wiener, "blurLB - blurC =  0")

c <- hypothesis(
  fit_wiener,
  "ndt_blurHB - ((ndt_blurLB + ndt_blurC)/2) > 0",
  dpar = "ndt"
)
d <- hypothesis(fit_wiener, "ndt_blurLB - ndt_blurC >  0", dpar = "ndt")

# Round numeric columns
round_hypothesis <- function(hyp) {
  hyp$hypothesis <- hyp$hypothesis |>
    mutate(across(where(is.numeric), round, 3))
  hyp
}

a <- round_hypothesis(a)
b <- round_hypothesis(b)
c <- round_hypothesis(c)
d <- round_hypothesis(d)

# Combine into a single tidy table
tab <- bind_rows(a$hypothesis, b$hypothesis, c$hypothesis, d$hypothesis) |>
  mutate(
    Parameter = c("v", "v", "T_er", "T_er"),
    Hypothesis = c(
      "High blur > (Low blur + Clear)",
      "Low blur  = Clear",
      "High blur > (Low blur + Clear)",
      "Low blur = Clear"
    ),
    `CrI*` = str_glue("[{CI.Lower}, {CI.Upper}]")
  ) |>
  rename(
    Mean = Estimate,
    SE = Est.Error,
    ER = Evid.Ratio,
    `Posterior Prob` = Post.Prob
  ) |>
  select(Hypothesis, Parameter, Mean, SE, `CrI*`, ER, `Posterior Prob`)

# Generate flextable
flextable(tab) |>
  theme_apa() |>
  width(j = 1, width = 2.5) |> # widen the Hypothesis column
  set_table_properties(layout = "autofit")
```

**A summary of the diffusion model results can be found in @tbl-diffexpt1A. There was strong evidence that high-blur red words were associated with a lower drift rate than both clear and low-blur red words, *b* = `r a$hypothesis$Estimate`, 90% CrI \[`r a$hypothesis$CI.Lower`, `r a$hypothesis$CI.Upper`\], ER = `r process_ER_column(a$hypothesis$Evid.Ratio)`. In contrast, the evidence supported the absence of a drift rate difference between low-blur red and clear words, *b* = `r b$hypothesis$Estimate`, 90% CrI \[`r b$hypothesis$CI.Lower`, `r b$hypothesis$CI.Upper`\], ER = `r process_ER_column(b$hypothesis$Evid.Ratio)`. There was also substantial evidence that non-decision time was greater for high-blur red words compared to both clear and low-blur red words, *b* = `r c$hypothesis$Estimate`, 90% CrI \[`r c$hypothesis$CI.Lower`, `r c$hypothesis$CI.Upper`\], ER = `r process_ER_column(c$hypothesis$Evid.Ratio)`. Additionally, the posterior distribution indicated that low-blur red words had a longer non-decision time than clear words, *b* = `r d$hypothesis$Estimate`, 90% CrI \[`r d$hypothesis$CI.Lower`, `r d$hypothesis$CI.Upper`\], ER = `r process_ER_column(d$hypothesis$Evid.Ratio)`.**

### Experiment 1B - DDM Results

```{r}
blur_rt_diff <- rts |>
  group_by(participant) |>
  dplyr::filter(rt >= .2 & rt <= 2.5) |>
  dplyr::filter(lex == "m")
```

```{r}
formula <- bf(
  rt | dec(corr) ~
    0 + blur + (1 + blur | p | participant) + (1 + blur | i | string),
  ndt ~ 0 + blur + (1 + blur | p | participant) + (1 + blur | i | string),
  bias = .5
)

bprior <- prior(normal(0, 1), class = b) +
  prior(normal(0, 1), class = b, dpar = ndt) +
  prior(normal(0, 1), class = sd) +
  prior(normal(0, 1), class = sd, dpar = ndt) +
  prior("normal(0, 0.3)", class = "sd", group = "participant") +
  prior("normal(0, 0.3)", class = "sd", group = "string")
```

```{r}
#| eval: false

make_stancode(
  formula,
  family = wiener(
    link_bs = "identity",
    link_ndt = "identity",
    link_bias = "identity"
  ),
  data = blur_rt_diff,
  prior = bprior
)

tmp_dat <- make_standata(
  formula,
  family = wiener(
    link_bs = "identity",
    link_ndt = "identity",
    link_bias = "identity"
  ),
  data = blur_rt_diff,
  prior = bprior
)
str(tmp_dat, 1, give.attr = FALSE)

initfun <- function() {
  list(
    b = rnorm(tmp_dat$K),
    bs = .5,
    b_ndt = runif(tmp_dat$K_ndt, 0.1, 0.15),
    sd_1 = runif(tmp_dat$M_1, 0.5, 1),
    sd_2 = runif(tmp_dat$M_2, 0.5, 1),
    z_1 = matrix(
      rnorm(tmp_dat$M_1 * tmp_dat$N_1, 0, 0.01),
      tmp_dat$M_1,
      tmp_dat$N_1
    ),
    z_2 = matrix(
      rnorm(tmp_dat$M_2 * tmp_dat$N_2, 0, 0.01),
      tmp_dat$M_2,
      tmp_dat$N_2
    ),
    L_1 = diag(tmp_dat$M_1),
    L_2 = diag(tmp_dat$M_2)
  )
}
```

```{r}
#| eval: false
#|

fit_wiener1 <- brm(
  formula,
  data = blur_rt_diff,
  family = wiener(
    link_bs = "identity",
    link_ndt = "identity",
    link_bias = "identity"
  ),
  prior = bprior,
  init = initfun,
  iter = 2000,
  warmup = 500,
  chains = 4,
  cores = 4,
  file = "weiner_diff_1",
  backend = "cmdstanr",
  threads = threading(4),
  control = list(max_treedepth = 15)
)
```

```{r}
fit_wiener <- read_rds("https://osf.io/gy5ab/download")
#fit_wiener <- read_rds("data/weiner_diff_noc (1).rds")
```

```{r}
#| label: tbl-diffexpt1B
#| tbl-cap: "Posterior distribution estimates for DDM (Experiment 1B)"
#| apa-note:  "95% CrI for equivalency tests. Posterior probability indicates the proportion of the posterior distribution that falls on one side of zero (either positive or negative), representing the probability that the effect is greater than or less than zero."

# Define contrasts using averages and differences
a <- hypothesis(fit_wiener, "blurHB - ((blurLB + blurC)/2) < 0")
b <- hypothesis(fit_wiener, "blurLB - blurC = 0")

c <- hypothesis(
  fit_wiener,
  "ndt_blurHB - ((ndt_blurLB + ndt_blurC)/2) > 0",
  dpar = "ndt"
)
d <- hypothesis(fit_wiener, "ndt_blurLB - ndt_blurC > 0", dpar = "ndt")

# Round numeric columns
round_hypothesis <- function(hyp) {
  hyp$hypothesis <- hyp$hypothesis |>
    mutate(across(where(is.numeric), round, 3))
  hyp
}

a <- round_hypothesis(a)
b <- round_hypothesis(b)
c <- round_hypothesis(c)
d <- round_hypothesis(d)

# Combine into a single tidy table
tab <- bind_rows(a$hypothesis, b$hypothesis, c$hypothesis, d$hypothesis) |>
  mutate(
    Parameter = c("v", "v", " T_er", "T_er"),
    Hypothesis = c(
      "High blur < (Low blur + Clear)",
      "Low blur = Clear",
      "High blur > (Low blur + Clear)",
      "Low blur = Clear"
    ),
    `CrI*` = str_glue("[{CI.Lower}, {CI.Upper}]")
  ) |>
  rename(
    Mean = Estimate,
    SE = Est.Error,
    ER = Evid.Ratio,
    `Posterior Prob` = Post.Prob
  ) |>
  select(Hypothesis, Parameter, Mean, SE, `CrI*`, ER, `Posterior Prob`)

# Generate flextable
flextable(tab) |>
  theme_apa() |>
  width(j = 1, width = 2.5) |> # widen the Hypothesis column
  set_table_properties(layout = "autofit")
```

**A summary of the diffusion model results is presented in @tbl-diffexpt1B. There was strong evidence that high-blur red words were associated with a lower drift rate than both clear and low-blur red words, *b* = `r a$hypothesis$Estimate`, 90% CrI \[`r a$hypothesis$CI.Lower`, `r a$hypothesis$CI.Upper`\], ER = `r process_ER_column(a$hypothesis$Evid.Ratio)`. In contrast, the evidence supported the absence of a drift rate difference between low-blur red and clear words, *b* = `r b$hypothesis$Estimate`, 90% CrI \[`r b$hypothesis$CI.Lower`, `r b$hypothesis$CI.Upper`\], ER = `r process_ER_column(b$hypothesis$Evid.Ratio)`. There was also substantial evidence that non-decision time was greater for high-blur red words compared to both clear and low-blur red words, *b* = `r c$hypothesis$Estimate`, 90% CrI \[`r c$hypothesis$CI.Lower`, `r c$hypothesis$CI.Upper`\], ER = `r process_ER_column(c$hypothesis$Evid.Ratio)`. Additionally, the posterior distribution indicated that low-blur red words had a longer non-decision time than clear words, *b* = `r d$hypothesis$Estimate`, 90% CrI \[`r d$hypothesis$CI.Lower`, `r d$hypothesis$CI.Upper`\], ER = `r process_ER_column(d$hypothesis$Evid.Ratio)`.**